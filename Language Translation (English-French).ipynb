{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb8bc032-9fce-4c04-b451-56d8494f3d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 15:34:22.555602: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-02 15:34:22.555630: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-02 15:34:22.556631: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-02 15:34:22.562152: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-02 15:34:23.348052: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import string\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80b9c624-f665-433d-bb95-cc285107eaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.15.0\n",
      "\n",
      "GPU is AVAILABLE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 15:34:25.684232: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-02 15:34:25.719269: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-02 15:34:25.719481: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print()\n",
    "gpu = len(tf.config.list_physical_devices('GPU')) > 0\n",
    "print(\"GPU is\", \"AVAILABLE\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6915b9d5-69f1-4ed6-8255-f1144eae52da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English words/sentences</th>\n",
       "      <th>French words/sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who?</td>\n",
       "      <td>Qui ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>Ça alors !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English words/sentences French words/sentences\n",
       "0                     Hi.                 Salut!\n",
       "1                    Run!                Cours !\n",
       "2                    Run!               Courez !\n",
       "3                    Who?                  Qui ?\n",
       "4                    Wow!             Ça alors !"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/eng-french.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18b3a180-5a44-423b-8107-b02df3305511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25570</th>\n",
       "      <td>She wants to dance.</td>\n",
       "      <td>[start] Elle a envie de danser. [end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25351</th>\n",
       "      <td>No one looks happy.</td>\n",
       "      <td>[start] Personne n'a l'air content. [end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96062</th>\n",
       "      <td>I can't come to work tomorrow.</td>\n",
       "      <td>[start] Je ne peux pas venir travailler demain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71943</th>\n",
       "      <td>Tom is a regular customer.</td>\n",
       "      <td>[start] Tom est un client régulier. [end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12526</th>\n",
       "      <td>This is our car.</td>\n",
       "      <td>[start] C'est notre voiture. [end]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               source  \\\n",
       "25570             She wants to dance.   \n",
       "25351             No one looks happy.   \n",
       "96062  I can't come to work tomorrow.   \n",
       "71943      Tom is a regular customer.   \n",
       "12526                This is our car.   \n",
       "\n",
       "                                                  target  \n",
       "25570              [start] Elle a envie de danser. [end]  \n",
       "25351          [start] Personne n'a l'air content. [end]  \n",
       "96062  [start] Je ne peux pas venir travailler demain...  \n",
       "71943          [start] Tom est un client régulier. [end]  \n",
       "12526                 [start] C'est notre voiture. [end]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source'] = df['English words/sentences']\n",
    "df['target'] = df['French words/sentences'].apply(lambda x: '[start] ' + x + ' [end]')\n",
    "df = df.drop(['English words/sentences', 'French words/sentences'], axis=1)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc4df642-5c28-4888-bd98-9e051321fa21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The button battery for my computer's timer died.</td>\n",
       "      <td>[start] La pile-bouton de l'horloge de mon ord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I only have one suggestion.</td>\n",
       "      <td>[start] Je n'ai qu'une suggestion. [end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He refused to pay.</td>\n",
       "      <td>[start] Il se refusa à payer. [end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop joking around.</td>\n",
       "      <td>[start] Arrête de chahuter ! [end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When did he go to Europe?</td>\n",
       "      <td>[start] Quand est-il allé en Europe ? [end]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             source  \\\n",
       "0  The button battery for my computer's timer died.   \n",
       "1                       I only have one suggestion.   \n",
       "2                                He refused to pay.   \n",
       "3                               Stop joking around.   \n",
       "4                         When did he go to Europe?   \n",
       "\n",
       "                                              target  \n",
       "0  [start] La pile-bouton de l'horloge de mon ord...  \n",
       "1           [start] Je n'ai qu'une suggestion. [end]  \n",
       "2                [start] Il se refusa à payer. [end]  \n",
       "3                 [start] Arrête de chahuter ! [end]  \n",
       "4        [start] Quand est-il allé en Europe ? [end]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle the data\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc4f79a5-14fa-4555-b716-1c3441f68010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122934, 35124, 17562)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data into train, validation, and test sets\n",
    "train_size = int(len(df) * 0.7)\n",
    "val_size = int(len(df) * 0.2)\n",
    "test_size = int(len(df) * 0.1)\n",
    "train_size, val_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5785292-bf5e-4510-9465-399bd712dd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[:train_size]\n",
    "val_df = df[train_size:train_size + val_size]\n",
    "test_df = df[train_size + val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32563c22-ba3b-4b17-aff0-58e0fb481631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The button battery for my computer's timer died.</td>\n",
       "      <td>[start] La pile-bouton de l'horloge de mon ord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I only have one suggestion.</td>\n",
       "      <td>[start] Je n'ai qu'une suggestion. [end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He refused to pay.</td>\n",
       "      <td>[start] Il se refusa à payer. [end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop joking around.</td>\n",
       "      <td>[start] Arrête de chahuter ! [end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When did he go to Europe?</td>\n",
       "      <td>[start] Quand est-il allé en Europe ? [end]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             source  \\\n",
       "0  The button battery for my computer's timer died.   \n",
       "1                       I only have one suggestion.   \n",
       "2                                He refused to pay.   \n",
       "3                               Stop joking around.   \n",
       "4                         When did he go to Europe?   \n",
       "\n",
       "                                              target  \n",
       "0  [start] La pile-bouton de l'horloge de mon ord...  \n",
       "1           [start] Je n'ai qu'une suggestion. [end]  \n",
       "2                [start] Il se refusa à payer. [end]  \n",
       "3                 [start] Arrête de chahuter ! [end]  \n",
       "4        [start] Quand est-il allé en Europe ? [end]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "140c4283-50c9-4dc5-92b4-ebc5e0d34a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGFCAYAAABg2vAPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABbd0lEQVR4nO3dd3Rc1bk28OdMbxr13m3LVe42tjHNBmzZ9BIg9NCSG0huCl+4uSQkJDekASFAIAmEllAMoffYBowb7t2S1XuXZkbT2znfH7JlC8m2ZM/oTHl+a2nZOjNz5pURM8/ss/d+BUmSJBAREVHcUshdABEREcmLYYCIiCjOMQwQERHFOYYBIiKiOMcwQEREFOcYBoiIiOIcwwAREVGcYxggIiKKcwwDREREcY5hgIiIKM4xDBAREcU5hgEiIqI4xzBARHFLEIQTfv3yl788rXO/8847IauVKJxUchdARCSXtra2gb+vWrUKDzzwAA4dOjRwzGQyyVEW0ZjjyAARxa2srKyBr8TERAiCMOjYa6+9hilTpkCn02Hy5Ml46qmnBh7r8/lwzz33IDs7GzqdDoWFhfjtb38LACgqKgIAXHHFFRAEYeB7okjFkQEiomG8/PLLeOCBB/Dkk09i9uzZ2LVrF+68804YjUbccsstePzxx/Hee+/h9ddfR0FBAZqamtDU1AQA2LZtGzIyMvD888+jrKwMSqVS5p+G6MQYBoiIhvGLX/wCjzzyCK688koAQHFxMQ4ePIi//e1vuOWWW9DY2IiSkhKcddZZEAQBhYWFA49NT08HACQlJSErK0uW+olGg2GAiOhrnE4nampqcPvtt+POO+8cOB4IBJCYmAgAuPXWW3HhhRdi0qRJKCsrw8UXX4xly5bJVTLRaWEYICL6GofDAQB45plnsGDBgkG3HRnynzNnDurq6vDxxx9jzZo1uOaaa3DBBRfg3//+95jXS3S6GAaIiL4mMzMTOTk5qK2txQ033HDc+5nNZlx77bW49tprcfXVV6OsrAy9vb1ISUmBWq1GMBgcw6qJTh3DABHRMB588EF8//vfR2JiIsrKyuD1erF9+3ZYLBb86Ec/wqOPPors7GzMnj0bCoUCb7zxBrKyspCUlASgf0XB2rVrsXjxYmi1WiQnJ8v7AxGdAJcWEhEN44477sCzzz6L559/HtOnT8e5556LF154AcXFxQCAhIQE/OEPf8C8efMwf/581NfX46OPPoJC0f+y+sgjj2D16tXIz8/H7Nmz5fxRiE5KkCRJkrsIIiIikg9HBoiIiOIcwwAREVGc4wRCIjqutQ1r8ey+Z6FQKKASVFAICigVSigFJQwqAxK1iUjWJSNZm4xkXTKStEmD/jSqjXL/CEQ0AgwDRHRcvd5e7O/Zf8qP1yg0SNImIUmXhBRdCnJNuRiXOA7jksahOLEYOcYcCIIQwoqJ6FQwDBBR2PhEHzrdneh0dw57u16lR6G5EMWJxShOLMa4xP6QUGQugkapGeNqieIXwwARycYdcKOitwIVvRWDjisFJXJMOShJKsHsjNmYkzkHU1OnQqXgSxZROHBpIREBAPYd2odVH62CIAgQBAFKhRJ1mjrs0O2QuzQA/aMIM9JnYG7mXMzNmIsZ6TOgU+nkLosoJjBmExEAoKG1AZX1lUhPTocECZIkwWqyAhHyfusOuLGlbQu2tG0BAKgVakxNndofDjLnYnbGbCRoEmSukig6MQwQ0QCtWovcrNyB771KL2pQI2NFx+cX/djTtQd7uvbguf3PQSEoUJJUgsW5i7Ekfwlmps/k5ESiEWIYIKKYIEoiDlkO4ZDlEJ7b/xzS9Gk4N+9cLC1YioXZCzkhkegEGAaIKCZ1u7vxZtWbeLPqTRhUBpyTdw7KispwVt5Z0Cq1cpdHFFEYBohiiN3jh83thy8gQpQkBEUgKEoQJQk5SXqkGOPz07Er4MIn9Z/gk/pPYFKbcF7+eVhRvAKLchZBrVDLXR6R7BgGiCJYt8OLhh4Xmi0u9Dh8sLr96HP7YXX1/93m9sPm8g8cD4jHXxz00BXTcf2CgjGsPjI5/A58UPsBPqj9AGaNGSuKV+DaSdeiJLlE7tKIZMMwQCQjSZLQZvOgvseJxh4X6ntcaOx1or7bhcZeFxzegNwlxrQ+Xx9WHVqFVYdWYU7GHFw76VpcWHQhRwso7jAMEI0RbyCI8jY79jRZsafZiv0tNjT0uOANiHKXRgB2du7Ezs6d+MO2P+DKkitxzaRrkGXMkrssojHBMEAUBqIooabLgd2H3/j3NttQ0WaHL8g3/kjX4+nBM/uewXP7n8PZeWfjuknX4cycM7lMkWIawwBRCPgCIrbX92J9dTd2NVqwv6WPQ/xRLigF8UXTF/ii6QsUJBTgmknX4PIJlyNRmyh3aUQhxzBAdIqael34orIL6w51YXNNN5y+oNwlUZg02hvx8PaH8eSuJ3HVxKtwx/Q7kKZPk7ssopBhGCAaIY8/iK9qe7DucACo7XbKXRKNMU/Qg5fLX8ablW/i2knX4rbptyFFlyJ3WUSnjWGA6AR6nT58uLcVq8s7sbWuBx4/r/lTfyh48eCLeL3ydVw/+Xp8q/RbvHxAUY1hgOhrPP4gPj3Qjnd3t+LLyq4Trt2n+OYOuPGP/f/Aa4dew41TbsTN026GWWOWuyyiUWMYIEL/Ln0bq7vxzq4WfHqgndf/aVScfif+tvdveKXiFdw89WbcNPUmGNVGucsiGjGGAYpr+5pteHtXC97f24ouu1fucijK2X12/GX3X/By+cu4ZdotuH7y9TCoDXKXRXRSDAMUd5zeAF7f3oR/fdWAmi5OAqTQs3qt+PPOP+PVilfxk/k/wfKi5XKXRHRCDAMUN5p6XXhhUz1e394Eu4d7AFD4dbo6ce+6e/F21du4f8H9yDfny10S0bAYBijmfVXbg+c21GFNeQc4F5DksLF1I6547wrcPv123F56OzTK+OweSZGLYYBiki8g4r09rXh+Yx0OtPbJXQ4RvEEvntr9FD6s/RD3L7gfi3IWyV0S0QCGAYopFqcPL26ux7++akS3gxMCKfI09DXgrtV3oayoDD+Z/xOkG9LlLomIYYBig93jx7Pr6/DchjrY2ROAosAn9Z9gQ8sG3DP7Hlw36TooFUq5S6I4xjBAUc3jD+LFTfX467oaWFx+ucshGhWH34Hfbf0d3q1+F7848xeYljpN7pIoTjEMUFTyB0W8trURT3xWjU7uD0BRrry3HDd+dCO+O/O7uH367VAICrlLojjDMEBRRRQlvLWrBX9eW4mmXrfc5RCFTEAM4PFdj2NDywY8dPZDyDXlyl0SxRHGT4oaH+9rw/LHvsS9b+xhEKCYtbNzJ65+72q8X/O+3KVQHOHIAEW8g619eODd/djeYJG7FKIx4fA78L8b/heJrXtxzhnfB7QJcpdEMY5hgCKWze3HI/85hJe3NCLI3YIozpydNAVnr/0jsOtN4BsvANkz5C6JYhgvE1DEkSQJr29vwtKHv8BLmxsYBCjupOtS8H+VOyBAAnprgGcvALY+I3dZFMM4MkARpbrTjp++tQ/b6nlJgOKTQlDgIY8GKc7uoweDXuCje4H6DcClTwA6s3wFUkxiGKCI4A0E8ZfPqvH0uhr4gxwJoPh1S8JULNzz0fA3HnwHaN8LXP86kFYypnVRbONlApLd5poeLP/Tl3j8s2oGAYpraXYF7tnzyYnv1Fvbf9mg7suxKYriAsMAycYXEPHrDw7i+me+Qn2PS+5yiGSl9ANPWS3QQDz5nT1W4J9XArteDntdFB94mYBkUdVhx3f/tR1VXQwBRADw3zYlpgRsI3+A6Afe/S7QUw2c/wAgCOErjmIewwCNuRc21uKhj8rhC8pdCVFkmNOnw7fslaf24A2PApY64PK/AmpdaAujuMEwQGOmx+HFPf/ais31fXKXQhQxTG4lHu+tP72THHgbsDUD170KmNgSmUaPcwZoTHxW3o4lf1zLIEB0DCEIPGp1IVHynf7JmrcBz54PdFac/rko7jAMUFh5/EHc9/pO3PbidvR5uVKA6FjftGmxyNMRuhNaG4B/LANqPg/dOSkuMAxQ2NR3O7Dskc+wamcbAE5uIjrWOLsG99mqQn9irw14+Wpg179Cf26KWZwzQGGxdn8LvvfabrgCcldCFHk0XgFPWdrC92lMDADv3gOIQWDuLeF6FoohDAMUcg9/sAt/2dACiaMBRENJwC9tInKDzvA/0fv/3f9XBgI6CYYBChm314e7nv0S65u84GUBouFdYNPhEucpLiMcNQYCGhmGAQqJmrZu3PL3jWh281eK6HjSnSr81lI9xs/KQEAnx1duOm1rd1fj+68fgFPkrxPR8SgCwF+sFuhGst1wyDEQ0Inx1ZtOy5MfbsOf1rcjyF8lohP6nlWFKT45W3MfDgSCAMy5WcY6KBLxFZxOSTAYxA+f/xzvVXkAgStUiU5ktk2HO051u+GQkoD3vt//VwYCOgbDAI2ay+3B7U+vxuZOBZujEJ2Eya3AE5Z6ucs4BgMBDcUwQKPS1tWN2//2BQ469HKXQhT5ROBhqzs02w2H1OFAICiA2TfKXQxFAI7v0ogdrKrDdY+vYRAgGqHrbFosDuV2wyF1eA5B9Vq5C6EIwDBAI7Ju627c+txmNPgT5C6FKCoU2TX4qTUM2w2HkhgA3vgW0FkudyUkM4YBOiFJkvDRui34wZvl6JQS5S6HKCpovAKeDud2w6HktQGvXAM4uuSuhGQUFb+rJA9JkvDmf9bjvg/rYBHMcpdDFB0k4AGbhLywbzccQtZG4LVvAn6P3JWQTBgGaFjBYBD/fP8z/GJtO+wKXhogGqmlNh0uczbKXcboNW8D3vkOILHVeDxiGKAhAoEAXnznP/jthl44FUa5yyGKGmlOFX4/5tsNh9CBt4HPfi13FSQDhgEaxOfz4/k3P8YjX9ngVhjkLocoasi73XAIrX8E2PWy3FXQGGMYoAEerxf/eP09PLGtD04lLw0QjcbdNjWmyrrdcAi9/99A3Xq5q6AxxDBAAACny41nXn0Hf9/lQJ8qSe5yiKLKLJsOd/XVyF1G6Ih+YNWNQHcUX/KgUWEYILjcHjzzylt4aa8dFnWa3OUQRRWjW4EnrA1ylxF6HivwyjcAT5/cldAYYBiIc16vDy/9+z28dsCOLk223OUQRRcReNjmQZLolbuS8OitBT78kdxV0BhgGIhjgUAAr733CV7e2Yl2bb7c5RBFnWusOpzlbpe7jPDa9waw+xW5q6AwY6OiOCWKIt76eC1e3FSLJm2J3OVQlHMecqL7o264G9wIWAMo+F4BzHOPblQlSRI63+6EZZ0FQVcQhhIDcm7OgTZLe8Lz9qzpQffH3QjYAtAV6JB9YzYM446ucml7tQ3WDVYIWgFZV2ch6cykgdtsW22wbrSi8IeFIf95AaDQocH9tkhoSzwGPvp/QP4CIHW83JVQmHBkIA5JkoSPPluPFz7bh1rtBLnLoRggekXoCnTIuSln2Nu7P+pGz+oe5NySg/EPjIdCq0D9I/UQfcdfhmfbYkP7a+3IuDwD4x8cD12+DvUP1yPQFwAA9O3qg22zDUX3FiHrmiy0PN+CgL3/tqAriI43O5B9c3gufal9Ap62tMfPC6jPAfz7W0Ag0rovUqjEze8yHfXZxq144aMNqNROBCDIXQ7FgIQZCci8KnPQaMARkiSh5z89yLg0A+Y5Zujydci7Mw8BSwB9O48/Oa37024kn5uM5LOTocvVIeeWHCg0Cli+7F++523zwjjZCH2xHkkLk6DQK+Dr6n+zan+9HSlLU6BJ1YT+h5WAn1kl5AccoT93JGvbA6x9UO4qKEwYBuLM5h178M93V+OgZjICUMpdDsUBf5cfAVsAxqlHd7NUGpTQj9fDXeMe9jFiQIS73g3TVNPAMUEhwDTNBFeNCwCgy9fBXe9G0BmEu94NySdBm6mFs9IJT4MHqRemhuXnWWLT4cpo3G44FDb/BahaI3cVFAacMxBHdh2owItvvI99imK4oJO7HIoTAVv/0L0qcfDLjcqsgt/mH/YxQXsQEId/jLetf+Z+wvQEuBa5UPNgDQSNgLw78yBoBbS+1Iq8O/LQ+1kvetb0QGVSIedbOdDlnv7vfKpThT9YYmg/gVGT+vsX/NcmwJQhdzEUQhwZiBOVtQ14ftU7OBjMQI+QJHc5RCGReUUmJv5hIkr+rwTmuWZ0f9AN01QTBKWArve6MO5/xyH53GQ0/735tJ+rf7thK3QIhqDyKObsAt7+NhsaxRiGgTjQ1WPBi2+8h0q7Go3KXLnLoThz5NP9kRGCIwJ9AagT1cM+RpmgBBTDP+browVHeFu9sG62IuPKDDgrnDBMMkBlViHxjER4GjwIuk/vTfy/rCpM8/We1jliRs1nwKbH5a6CQohhIMZ5vF78860PsK+pF9W6iXKXQ3FIna6GKlEF50HnwLGgOwh3jRv68fphH6NQKaAv0sNx8OgkPUmU4DjogGH80AZakiSh5cUWZF2XBaVOCUmUIAX7P7lKgcOfYE+jf9CMPh2+Y6899RPEorW/Blp3yV0FhQjDQAwTRRFvfrQGG3eVo9Y8EwGJ/7kpPIKeINwNbrgb+icE+rp9cDe44evxQRAEpC5LRef7nejb1QdPkwfNf2+GKlkF85yjqw/qfl+HnjU9A9+nLU+DZZ0Flg0WeFo9aH2pFaJXRPLZyUOe37LOAlWCCubZ/eczlBjgLHfCVe1C93+6oc3RQmk8tQmzRrcCT1hicLvh0yX6gfe+D4hxftkkRnACYQxb99UOfLJuM5qSZsIhDj8cSxQK7jo36n9fP/B9+6v9u/IlLU5C3p15SFuZBtErovX51v5NhyYaUPTjIig0RwOqr9M3sE8AACQuSETAHkDn250Dmw4V/bhoyGWCgC2Arve7MO5n4waOGcYZkFaWhoY/NUBlViH3zlO8PCYCf7B5kBKr2w2frva9wNZngIXfkbsSOk2CJHEWSCw6WFWLJ557BZVSFmrAngMEPHTFdFy/oOC4t3/w+QdY9eEqTJkwZeBYtbIa2zTbxqK8iHS1RYtfWKvkLiOyac3APduAhCy5K6HTwHHjGNTR3YN/vvk+Wt0K1IL/gxKdigK7Bj9nEDg5bx/wyU/lroJOE8NAjHF7PPjnvz9AdWM76oxTIXGHQaJRU/sEPG2No+2GT9eBt/pXGFDU4u96DBFFEf/+cA227z0Ia/oM9AU5T4Bo1A5vN1wQb9sNn64P7wUCnFsRrRgGYsiXW3Zi9frNUKaPQ5V36B7xRHRy59r08bvd8OnorQE2/EnuKugUMQzEiOa2Drz9yVoIWiN2+jlhkOhUpDhVeNhSLXcZ0Wv9o0BPPG/XHL0YBmKAz+fHa+99gs7uXtTrJsItsgER0WgpAsCT3G749AS9wEf3yl0FnQKGgRjwny83Yce+ckhZU9DgHX5HNyI6sW/b1JjO7YZPX81nwP635K6CRolhIMpV1jbgg7XroUtMxw5XeFq2EsW66X06fLePw9sh8+n/Aj7nye9HEYNhIIo5nC689t4ncDhcKFcWw8/tholGzeBR4AkLJwyGlL0N2PI3uaugUeC7R5SSJAnvr1mHg5U1QOYktPu0cpdEFH1E4A9WL1JFj9yVxJ5NTwBeu9xV0AgxDESpXQcqsPrLr5CWkYmdrqGNW4jo5K6y6XCuu03uMmKTuxf46mm5q6ARYhiIQr1WG/79wWoERRH1yjy4uHqAaNTyHRr8jNsNh9fmJwG3Ve4qaAQYBqKMJEl4++PPUNPQjOScIhxwGuUuiSjqqH0Cnra0QwX2aQsrjw3Y/Be5q6ARYBiIMnsOVmLDtl3Iz83CV/Zk9h4gOgX/awUKud3w2NjyV8DFJZuRjmEgirg9Hrz7n88RDAbRrcrgpEGiU3C2VY+rnQ1ylxE/vH3ApsflroJOgmEginyxaTsqquuQk5uLrX3sPUA0WskuFR7hdsNjb8vfAWe33FXQCTAMRIm2zm58/MUGJJoTsN+bykmDRKOkCABPWmzQc7vhsed3solRhGMYiAKSJOH91evQ0d0LfUo2Jw0SnYI7bWrM8PXIXUb82vYPwN4hdxV0HAwDUWDPwUps3rEHBTlZ2OZI4qRBolGa1qfFPdxuWF4BN7DhUbmroONgGIhwx04adGtT0ezVyV0SUVQxeBT4i6VJ7jIIAHa8CLgtcldBw2AYiHBHJg0W5udguz1B7nKIoosI/M7q43bDkSLgBna9LHcVNAyGgQh27KTBTjGBSwmJRukKmw5L3K1yl0HH2v4cIHGzp0jDMBChJEnCJ59vRGd3L7Iz0jkqQDRKeQ4NHuB2w5Gntwao+UzuKuhrGAYiVF1jCzbv2IPszAw0+Qzo8WvkLokoaqh8Ap6ydHC74Ui17R9yV0BfwzAQgSRJwn++3IQ+pxMpSWbscpjkLokoqvzUBhQH2D43YlV+Alg5qTOSMAxEoEM19di25wDysjPR6NVxVIBoFM6y6XCNg9sNRzQpCOx4Xu4q6BgMAxFGFEV8um4T3B4fkswJ2MW5AkQjluxS4WFLrdxl0Ejs/CcQ8MldxSDnnXcefvCDHwx8X1RUhMcee+yEjxEEAe+8885pP3eoznOqGAYizIHKGuw6UIH8nEw0erTo5qgA0YgoAsDjFhuMUkDuUmgknJ1A+XshO90ll1yCsrKyYW9bv349BEHA3r17R3XObdu24a677gpFeQN++ctfYtasWUOOt7W1YcWKFSF9rtFgGIggoihizfot8PsDSDAZsZdzBYhG7A6bBrO43XB02fZsyE51++23Y/Xq1Whubh5y2/PPP4958+ZhxowZozpneno6DAZDqEo8oaysLGi18i0fZxiIIAerarG3vBJ52Zno9au4rwDRCE3t0+J7fexGGHUaNwPt+0Nyqosvvhjp6el44YUXBh13OBx44403cPnll+Ob3/wmcnNzYTAYMH36dLz66qsnPOfXLxNUVVXhnHPOgU6nw9SpU7F69eohj7nvvvswceJEGAwGjBs3Dj//+c/h9/sBAC+88AIefPBB7NmzB4IgQBCEgXq/fplg3759WLp0KfR6PVJTU3HXXXfB4XAM3H7rrbfi8ssvx8MPP4zs7Gykpqbi7rvvHniu0WIYiBCiKGLthi3w+f1IMBnZjIhohPQeBZ7izPToFaLRAZVKhZtvvhkvvPACpGM2NXrjjTcQDAZx4403Yu7cufjwww+xf/9+3HXXXbjpppuwdevWEZ1fFEVceeWV0Gg02LJlC/7617/ivvvuG3K/hIQEvPDCCzh48CD+/Oc/45lnnsGf/tTfsfHaa6/Fj3/8Y0ybNg1tbW1oa2vDtddeO+QcTqcTy5cvR3JyMrZt24Y33ngDa9aswT333DPofp9//jlqamrw+eef48UXX8QLL7wwJAyNFMNAhCivrsPug4eQm50Jryigxq2XuySiyCcCv7X6kBrkdsNR68BbIZtIeNttt6Gmpgbr1q0bOPb888/jqquuQmFhIe69917MmjUL48aNw/e+9z2UlZXh9ddfH9G516xZg4qKCrz00kuYOXMmzjnnHDz00END7vezn/0MZ555JoqKinDJJZfg3nvvHXgOvV4Pk8kElUqFrKwsZGVlQa8f+lr/yiuvwOPx4KWXXkJpaSmWLl2KJ598Ev/85z/R0XG082NycjKefPJJTJ48GRdffDEuuugirF27drT/bAAYBiKCJEn4YtM2eL1+mE1GHHIZEJD4n4boZC6z6XA+txuObh5byHYknDx5Ms4880w899xzAIDq6mqsX78et99+O4LBIH79619j+vTpSElJgclkwqefforGxsYRnbu8vBz5+fnIyckZOLZo0aIh91u1ahUWL16MrKwsmEwm/OxnPxvxcxz7XDNnzoTReHSEePHixRBFEYcOHRo4Nm3aNCiVyoHvs7Oz0dnZOarnOoLvOBGgqbUde8orkZ2ZBkkCynmJgOikch1q/JLbDceGA2+F7FS333473nzzTdjtdjz//PMYP348zj33XPzxj3/En//8Z9x33334/PPPsXv3bixfvhw+X+iWN27evBk33HADVq5ciQ8++AC7du3C/fffH9LnOJZarR70vSAIEEXxlM7FMBABtuzahz67E0nmBDR6tbAHVXKXRBTRVD4BT1s6ud1wrKj4CPCH5lLPNddcA4VCgVdeeQUvvfQSbrvtNgiCgI0bN+Kyyy7DjTfeiJkzZ2LcuHGorKwc8XmnTJmCpqYmtLW1DRz76quvBt1n06ZNKCwsxP3334958+ahpKQEDQ2DN8DSaDQIBoMnfa49e/bA6XQOHNu4cSMUCgUmTZo04ppHg2FAZja7A5t27EFKkhmCIOAgRwWITuo+m8DthmOJzw5UD52ZfypMJhOuvfZa/PSnP0VbWxtuvfVWAEBJSQlWr16NTZs2oby8HN/+9rcHXX8/mQsuuAATJ07ELbfcgj179mD9+vW4//77B92npKQEjY2NeO2111BTU4PHH38cb7/99qD7FBUVoa6uDrt370Z3dze8Xu+Q57rhhhug0+lwyy23YP/+/fj888/xve99DzfddBMyMzNH/48yAgwDMtu1vwIdXT3ISE+F1a9Ci5fLCYlO5EybDtc56uUug0Jtf2gvFVgsFixfvnzgGv/PfvYzzJkzB8uXL8d5552HrKwsXH755SM+p0KhwNtvvw23240zzjgDd9xxB37zm98Mus+ll16KH/7wh7jnnnswa9YsbNq0CT//+c8H3eeqq65CWVkZlixZgvT09GGXNxoMBnz66afo7e3F/PnzcfXVV+P888/Hk08+Ofp/jBESJImNpeUSCATw0JP/QF1jC8YX5WOTNREHXRwZoPB46IrpuH5BwXFv/+DzD7Dqw1WYMmHKwLFqZTW2abaNRXkjkuhS4tPOJu4yGIs0JuAntYCKH4jkwJEBGR2sqkV1fROyM9MRkIAqLickOi4hCDxhtTMIxCqfA6hdd/L7UVgwDMhEkiRs2r4bwWAQBr0OjR4d/FxOSHRct1k1mO3tlrsMCqeKD+SuIG7x3UcmLe2d2H3gEDLSUgGAmwwRncDkPi1+wO2GY1/lJwCvXMuCYUAmW3fvh7XPjpQkM3yigGaPTu6SiCKSzqPAU9ahzWcoBjk6gObImaMSTxgGZOB0ubFx224kJfYvJ6z36BCEIHdZRJFHBH5r8yE96Ja7EhorFR/KXUFcYhiQwcGqWrR3dSOTlwiITugSmw4XuLjdcFypXiN3BXGJYUAGuw9UAADUahXcQQVaubcA0RA5DjUe5HbD8afzIOC2yl1F3GEYGGPWPjv2HKxEanIiAKDOo4PESwREg6j8Ap62dEHN7YbjjyQCjV+d/H4UUgwDY6y8qha9VhtSkpMA8BIB0XD+n1XAuECf3GWQXBo3yV1B3GEYGGM795VDoVBApVTCEVSgw6eRuySiiLLIpsP13G44vjVslruCuMMwMIa6e604UFmDtJQkAECtWw/wEgHRgESXEo9aauUug+TWugvwcwXJWGIYGEMHq2pgsfUhJal/vkAj9xYgGiAEgT9b7TBxu2ES/dxvYIwxDIwRSZKwfe9BqNVqKBQK+EUBnbxEQDTgW1Yt5nK7YTqClwrGFMPAGGnv6kFlTf3AJYI2nwYiLxEQAQAm2bX4YR+XEdIxOIlwTKnkLiBeHKysgbXPgZysDABAC/cWIAJweLthS/RuN/zb9V68VeFHRbcIvUrAmflK/P4CLSalKQfu4wlI+PGnHrx2IABvQMLyCSo8tVKHTNPxP49JkoRffOHFMzv9sHokLM5X4umLdChJ7T+vNyDhjvc9eLfCjyyTAk9dpMMF446+pP9xoxeNNhFPrIzSFUtN24BgAFDybWoscGRgjOzYVw6tVgOFov+fvJlhgAiQgN/YfMiI4u2G1zUEcPd8Db663YjVNxngF4Fl/3LB6Tu6R8IPP/Hg/coA3viGHutuNaLVLuHK10/8M/9how+Pb/HhrxfpsOUOI4waAcv/5YIn0H/ev+/wY0drEJtvN+KuuWpc/6Yb0uEmP3UWEc/s9OM350fxvCS/E2jbI3cVcYNhYAz0Wm2ob25FSpIZAOAMKmALqGWuikh+F9t0WBbl2w1/cqMRt87SYFqGEjOzlHjhMh0abRJ2tAUBADaPhH/s8uPR5TosLVZhbo4Sz1+mw6amIL5qHn6ypCRJeGyLDz87R4vLJqsxI1OJly7Xo9Uu4Z2K/seUdwdx6SQVpmUocfd8DbpcErpd/WHgvz504/cXaGHWRvmlSF4qGDMMA2OgrqkVtj47Es0JADgqQAQA2Q41fmWJvXkCNm//nyn6/jfiHW1B+EUMGsKfnKZEQaKAzU3BYc9RZ5XQ7pAGPSZRJ2BBnnLgMTMzldjQGITbL+HTmgCyTQLSDAJe3uuHTiXgiikx8IGDOxGOGV6MGQM1DU2QJAkqZf+1Ps4XoHin9ANPWWNvu2FRkvCDTzxYnK9EaUb//+/tDgkaJZCkG/wpPdMooN0x/M/f7hAH7jPkMc7+226brcbejiCmPuVAmkHA69/Qw+IBHvjCgy9uMeJnn3nw2n4/xqco8NyleuSao/CzX8cBuSuIGwwDYSaKIvaVV8FoNAAAJAlsTERx78dWJSb4Y2+74bs/9GB/ZxAbbjOG/bnUSgF/uWjw5MBvvevG98/QYFd7EO9UBLDnOyb8YaMX3//EgzevMYS9ppCzNgIBL6Dia2a4RWFUjC6tHV1o7+pG8uFLBD1+NTyi8iSPIopdC2w63OSok7uMkLvnIzc+qArg81uMyDvmU3iWSYAvCFg9g0cBOpwSskzDX9PPOrzKoMM5zGOMw79sf14XwIHOIO45Q4Mv6oNYWaKCUSPgmmlqfFE//OWIiCcFgZ5quauICwwDYVbX2AKHy40EU/8nBV4ioHhmdinxWIxtNyxJEu75yI23KwL47GYDipMHv6zOzVZCrQDW1h6dLHioO4hGm4RF+cN/MChOEpBlEgY9ps8rYUtzcNjHeAIS7v7Ig79drIdSISAoAv7D7/9+EQiKUXw5prtS7griAsNAmFXWNkAhCBCE/k8Anf4YmNRDdAqEIPCYzRFz2w3f/ZEH/9rrxytX6pGgFdDuENHuEOH2978BJ+oE3D5bjR/9x4PP6wLY0RrEt971YFGeEgvzjplU+KQDb5f7AQCCIOAHCzT4v/VevHfIj30dQdz8ths5CQIunzz06u6v13mxskSF2dn9QWFxgRJvVfixtyOIJ7f6sLggiq8IdzEMjIUo/g2JfF6vDweqagZWEQD9lwmI4tHNNg3mexrlLiPknt7e/wZ+3ouuQcefv0yHW2f1bzn+pzIdFJ96cNXrLniDwPLxKjx10eA9AA71iLB5j36C/8liDZx+CXe974HVI+GsAiU+udEAnWrwpYX9nUG8fjCA3d8+Ok/h6qkqfFGvwtnPOzEpVYFXrorC+QJHcGRgTDAMhFF9cyt6LTbkZvfvOugRBTiC/Cen+FNi1+JeW+wtIwQA6Rfmk95Hp+qf7Pf1CX8nOo8gCPjVEh1+teTEGweVZihR9T3ToGMKQcBTF+nx1AmeL2owDIwJXiYIo7qmFnh9fuh1/f8zd7MxEcUhrVeI6u2GSWY91f3LsCisGAbCqKq2AWr10ZGAbl4ioHgjAf9nDSArircbJpn5XYCtSe4qYh7DQJj4/QHUN7chwXj0Wh3DAMWbFTYdylwtcpdB0Y6TCMOOYSBMOrp70OdwwMQwQHEqy6HG/1m4RpxCgPMGwo5hIEzau3rgdLlhNPRP4OHkQYon/dsNd0MDUe5SKBYwDIQdw0CYtHV2AcBAy2JOHqR48iObEiV+m9xlUKzoja2NqiIRw0CYNDS1QqU6OhLA/QUoXpxh0+Fme+xtN0wycvXIXUHMYxgIg0AggLrmVs4XoLjTv90wgwCFGMNA2DEMhEFHdy/67I5BKwn6gmxORLHtyHbDCZJf7lIo1rh65a4g5jEMhEF7Vw9cx0weBAB7gJMHKbb1bzfcJXcZFIuCXsBrl7uKmMYwEAZtnV2QcHTyoFcU4JP4T02xa0KfFvfauIyQwoiXCsKK71Bh0NA8ePKgnZcIKIZpvQKetnK7YQozhoGwYhgIMUmS0NjczksEFB8k4NfWILcbpvDjvIGwYhgIMYfTBYfbBZ326L4CDo4MUIxaYdNhhYujAjQGnN1yVxDTGAZCzNpnh8fjg06rHTjGywQUizK53TCNJV4mCCuGgRCz9tnh9XoHjQzwMgHFGqUfeNraw+2GaewwDIQVw0CIWW12BCUJSuXR0QCODFCs6d9u2Cp3GRRPGAbCimEgxKx2O4SvHeOcAYol87jdMMmBYSCsGAZCrLvHCkE4GgfcQQUC3GOAYkSCW4nHud0wycHPFSvhxHepEGvv7h40edAj8p+YYoMQBP5kdXK7YZKJJHcBMY3vVCEUDAbR1WMZNHnQJ339ogFR9JCkoy/AN9q0WODplLEaIgoXhoEQ6nM44fZ4odMdHRnwcWSAolhnZxsAYLxdi5/YqmSuhojChe9UIWTrc8Dr9UGr4cgART+LpRtdna3QegX81dIidzlEFEYMAyHU53DA6/MNvkzAkQGKQsFAANt3bIRJUOBX1iCygi65SyKiMOI7VQh5vD6IkjTQrRBgGKDotHPXZijcLnwjZTpm+LUIgBtnEcUy/h8eQl6vb9CyQoCXCSj6NDTUoKutCWeOm4zElBJ8iRKoJB9yfLUo8FUh21cHNbiigCiWMAyEkNfnA6TBy184MkDRxO1xob5qP4rMyZhRUjpwPCBo0KidjEbtZCglP7J99cj3VSHXXwON5JOxYiIKBYaBEPL4fEN2H+TIAEULURTR0dqIBAk4b87iQZe7jhUU1GjWlqBZWwKFFESWvwH5vkrk+WqglTxjXDURhQLDQAj5fH6IX9sXgyMDFC26Whuh9nkxt3AitBrtyR8AQBSUaNWMQ6tmHLZKIjL8TSjwVSHPVwW9xEmHRNGCYSCEnC43BMXgkQA/RwYoSlyx4htQ2W2wtzWhpaYcEBQwJ6ciISkVStXJXyokQYEOTSE6NIXYJp2P9EALCnyVyPNVwSg6xuAnIKJTxTAQQk6XGyrl4KZEQYYBihIpaZm45bv3w27tRVNNOeoP7UNdxV601B0CICAhKRkJSWlQqdUnP5kgoEudhy51HnYYliA10I58XyXyfVVIEG1h/1koFvG1NJwYBkJouDDAX1+KNglJKZg6dzGmzl0Mp92GpppyNBzaj9ry3WhrqIIkSjAlJiMhOQ3qYzbYOi5BQI86Gz3qbOw2novkQAfyfVXI91UhMdgb/h+IYoM2Qe4KYhrDQAg5XW4oVV8LAwKba1D0MiYkYvKshZg8ayHcTgeaaytQf2g/ag/uREdTDYLBIIzmJJiT06DR6kZ0TosqExZVJvYazoI50IOCwyMGycGuMP80FNUMqXJXENMYBkLI5fFwZIBilt5oQsn0eSiZPg9e9zVorjuEhsr9qNm/E50t9Qj6AzCYE5GYnAaNTj+ic/apUrFftQj7DYtgClqQ76tCgbcKqcH2MP80FHUYBsJKkCSJH11DQBRF/PhXj8AfDCArPW3g+IfdqWjzjWxmNlE4JWhVWDolAytKs3DepAzo1MqTP2gEfF4PWuoq0Vh9EFX7tsPS1Q6/zwuDyQxzShp0euOoz2kI9h2+lFCJ9EArQzUBZb8HFn5H7ipiFsNAiEiShB89+PCQMPBRdypaGQYowujVSpw3KR0rpmdj6eQMmLShGST0+3xoa6hCY3U5KvduQ29nK3xeD/TGBJiT06AzGIfs0nkyOtGBfF818r1VyAg0QcG+9vHpymeBGd+Qu4qYxTAQIpIk4Ue/ehg+fwDZGUfDwMc9KWjxjuxaKpEcNCoFzilJQ1lpNi6ckolEwwhWC4xAwO9He2MNGmvKUbV3G3o6WuBxOaEzmGBOSYPemDDqYKAVXcjzVSPfV4VMfyOUEENSK0WBG98CJpwvdxUxi2EghH78q0fg8XqRnZk+cOyTnhQ0MwxQlFArBSwcl4qV07OxbGomUk2hGdUKBoPoaK5D0+ERg+62Jrhddmh1BphT0mEwmUcdDNSiB7n+WuR7K5Htb4AKgZDUShHqrnVAziy5q4hZDAMhdO+vH4HL40XOMWHg054UNDEMUBRSKgTML0rGitJslJVmIdMcmt9jURTR2dKApppyVO/bjo7mergcfdDo9DCnpMGYkDTqYHCkkVK+rwo5bKQUm36wH0jKl7uKmMUwEEL3/eYx2J1O5GRlDBz7T08KGhkGKMoJAjA7Pwkrp/cHg7xkQ0jOK0kSutua0FRTgap929HeVAuX3QaVRgNzchqM5uTj9kg4HqXkR7a/HvleNlKKKfe3A+qRrVKh0WMYCKH/+e2fYbM7kHtMGFjdm4wGD3+BKbZMz01EWWkWVk7PRnHa6FcLDEeSJPR2tqKppgLV+3egtb4Kzj4blGo1zMmpMJmToVCObgXE0UZKVcj1VUPHRkrRSW0A7m+Tu4qYxjAQQj/93eOw2PqQl505cOyz3mTUMgxQDJuclYCy0iysKM3GpKzQ7BInSRKsPZ1oqi5HzcGdaK49BIfNAqVCiYTkVJiSUqEcZTAQ2EgpeiXmAz/cL3cVMY1hIITu//0T6LHaBoWBDdZEVLhC88mJKNKNSzMOjBiU5iaG7Lx9vd1orClHXfkeNFTth8PaO+pGSoNIEtIDLQPbIhtFe8hqpTDIngl8+0u5q4hpDAMh9PM//gWdPb3Iz8kaOLatLwF7HNxTm+JPfooeZdOyUFaajTkFo58UeDwOmwWN1QcHGinZbb2AhNE1UjqWJLGRUqSbcCFw47/lriKmMQyE0C8eeQrtXT2DwsBehxFb+0L3CYkoGmWZdVg+LRMrpmfjjKIUKBShCQZOu62/X0LFPtSW70afpQeSKMKYmAzzSBspfU1SoHOgXwIbKUWIBd8BVvxe7ipiGsNACP3y0b+itaMTBbnZA8cqnAZssCXJVxRRhEkzaXDh1CysKM3CmeNToVKObrXA8QxqpFS+C7aezlNqpHQsNlKKEBc9Asy/Q+4qYhrDQAj94anncai2HsUFeQPH6tw6rLWkyFgVUeRKMqhxwZRMrCjNwlkladCqQtMvwet2DWqkZOnpGGikZE5Og3aEjZSOxUZKMrrlA6D4bLmriGkMAyH01IursGX3PpQUFw4ca/dq8EFP2gkeRURAfyOlJZOPNlLSa0LbSKmpuhyV+7aFuJFSFdICreyXEG4/rgQSMk9+PzplDAMh9M83P8DHX2zE1JJxA8dsASXe6OQvMdFoHGmkVFaahfOnZIa2kVJjNRqrDqJy7zZYOtvg9bqhN5pgTk5nI6VIpEsE/qdR7ipiHsNACL398Vq88eFqTJ04fuCYTxTwUnv2CR5FRCeiUSlw9oQ0rJge2kZKwUAAbY01/a2XQ9hIKddXgwJfFTL9DWykFAp584E71shdRcwLTdwmAIBWqx3y4qFRSFBCQpAd2YlOiS8gYm1FJ9ZWdA40UlpRmo1l0zKRdhqNlJQqFfLGTULeuElYcP6lA42UqvZuQ1dbEzpb6kfdSMmrMKBWNx21uulspBQqaRPlriAucGQghD7ftA3PvPLmoJEBAHitIwOOIHMXUSiFu5FSc20FqvZu62+k5LRDo9Ud7pdwqo2U6pDvq2QjpdG64EHgrB/IXUXMYxgIoa279+NPz/4LU0vGDXqxeK8rDZ3+0a93JqKROdJI6UgwyE+JlkZKtdBI3pDUGrOuexWYvFLuKmIew0AIHaiswW+f/AcmFOVDdcz2qF9YklDtDs2LExGd3JFGSitKszAu3RSSc/Y3Umrrb718bCMllQrmlLRTbqSU6W9Ega+SjZSO53s7gdTxJ78fnRaGgRBqaG7Fg3/6G7Iy0mDQHx2y3GU3YYfdLGNlRPFrUubhRkrTszA5KzT/Hx7bSKn24G401ZaHppFSoAn53irk+6qhl5whqTWqKTX9rYsVoVlmSsfHMBBCXT0W/PyPTyLBZESi+Wg/glq3Dp9x4yEi2R1ppLSiNBvT80LbSKmptgK1B3f3N1KyWQBBgDmJjZROS/pk4O4tclcRFxgGQsjt8eAnv3kMCoUC6anJA8d7/Cq83ZUhY2VE9HV5yXqsKA1PI6WmmnLUVewd1EjJdLhfwqk3Uqo63EjJGpI6o8L0bwBXPSt3FXGBYSCEJEkaaGN8bLMivyjgxfYsgMsLiSLSkUZKZaXZOKM4BcoQNVJyOfrQVFPe30ipYg/6ertD1EipCvm+ythvpHTRo8D82+WuIi4wDITYX154DVt278fEcYWDjr/SngmXyOteRJEu3I2UGioPoObgzpA1Usr3VaHAVxmbjZS++xWQMUXuKuICw0CIDbcLIQB82J2KNt+pb5BCRGMvUX+0kdLZE0PfSKmx8gCq9+8IUSMlK/IPd1hMC8RAIyV9CvCT2v51oxR2DAMhtu6r7fjrP9/AtEkTBh3fYE1EhWv0DVGIKDKYtCosDVMjpdb6KjRWHUTVvu2wdLXBx0ZKwKSLgG++IncVcYNhIMT2VVTh9395DhPGFUJ1zNKivQ4jtvaFbvYyEclHr1bi3InpWDE9GhopOZHnq0KBrwoZ/ihqpLTsN8CZ98hdRdxgGAixlvZO/PLRp5GSlIgE09FE3+DRYnVvqoyVEVE4HGmkVFaahWVTs8LTSGnfdvS0N8PjdkGnN4aokVIjlAiGpNawuPMzIHeu3FXEDYaBEPN4vfjJb/4EQEBG2tG9BdjKmCj2qRQCFo0PTSOlYwWDQXQ016G5pgKVe7ehq7URbpcDWp0e5uQ0GBISRx0M1KIXuf4a5HurkO2vj6xGShoTcF8DoGRPl7HCMBAGv3z0r2hp70BhXs7AMUkC/tWeBa8UmpnJRBTZFAIwvyhlYC+DrMQwNVJqaYDL0RdbjZTGLQFufkfeGuIMw0AYPPvqW/hi83ZMnlA86PgnPSlo9obmBYGIoocgALPyk7AyHI2U2pvRVN3fL6GtsQYuuw1KtQaJKafWSEkhBZDtr0eBt1K+RkpL7gfO/cnYP28cYxgIg/fXrMMrb380ZEXBTrsJO9mjgCjuleaasaI0O2yNlGoO7ERLXWXIGinl+yqRN5aNlG75ACg+e2yeiwAwDITFpu278cTzr2LqxPGDhuuaPVp8wkmERHSMMWuk1GeFUlBEfiMlpQb4nyZAzVHUscQwEAZVdY34zRPPIDcrE3rd0QlEPlHAS9yWmIiOo/hwI6WVY9RIKSEpBeaktMhqpJS/ELj909Cdj0aEYSAMXG4P7nvoMQjC4BUFAPDvznRYA6FZekREsSsvWY+yaf0jBnMKksPSSKn+0F70WU+zkRKAVH9b6Bopnf8AcPaPT+8cNGoMA2Hyx7++gIOVtRhflD/o+JfWRFRyJ0IiGoVMsxZl07LC10jp0H7Ulu9GX283RFE8HAxSodaMfmnkaTdSunsrkD5p9I+j08IwECbvfPo5Vr33KaZNGtyjoMJpwAZbkjxFEVHUSzVqsOxwh8Uzx6dCHQWNlPJ9lUgZSSOl1AnA93acQvV0uhgGwmT73oN49O8vYdL4YiiP+Z+116/CW10ZMlZGRLEibI2UPG601B1Cw6H9hxspdSLo98OQYIY5JT18jZTO/D6w7NenWT2dCoaBMGnr7MYvHnkKSeYEmBOOLh2SJOCl9iz4ufkQEYWQSavCksONlJaEsJGS3+dFS13loEZKfp8PelPCaTZSqkZG3x7kqSwQjvRLuO1ToGBhSOqm0WEYCJNgMIj7//AkrH125GUP3ob4454UtHDzISIKk2MbKS2dnIEEXWgmLR/bSKlq3zb0drTB63VBb0wYdSMlSZLQWLkfl159HaYZLUDtF8A3XgJGuUkShQbDQBg999rbWLtxK6aUjBt0fL/DiK/YwZCIxoBGpcBZE9KwojQLF07NRJJBE5LzHmmk1FRTjsq92/obKbmc0BlMI2qk5OizwmW34aYf/gqpmbkhqYlOHbtAhFFhXg5EURxyPF/nYRggojHhC4j4rKITn1V0DjRSKivNwvJpWafVSEmpUiFv3CTkjZuEM5Zegs6WejRVlw80UupsaThhIyW7pQfZheORkpFznGegscSRgTCqqK7Db5/8BwrysqHVDE7jr3dkoC/ILEZE8ghnI6Wu1kY01ZQPaqSk1miRmJIOozkJANBwaB8uvPpbmL/kopA8L50ehoEwsjuc+OnvHodSpUR6SvKg276ymbHfGZo9yYmITseRRkorSrOwojQ77I2UBKUSarUW3/zez5FTOOHkJ6KwYxgIs4f/9hL2VVSipLhw0PEWrwYf96TJVBUR0fEdaaRUVpqF8SFupNRcW4Hq/TugUmtw8Y13j34rZAoLhoEw+8+Xm/Hcqncw7WtNi4IS8C8uMSSiCDcx04Sy0mysDHEjJQAh22KZTh8jWZhNKMyHUa+D0+WGyXh06E0pADlaLxo8o9+8g4horFR2OFDZUYXH11YNNFJaUZqFGXlJp3xOhoDIw5GBMAsEAnjg4afQbbGhIDdr0G3cmpiIolW4GimRPBgGxsCq9z/FO59+hmkTB0+UcQYVeLUj6ziPIiKKDplmLZZPy0JZaRYWFKeGrJESjR1esB4DE8cVQqlQwu8PDDpuVIpIVftkqoqIKDQ6+rx4aXMDrn9mC874zRq8u7tF7pJolBgGxsCEwnwkJ5phsdmG3Fak88hQERFRePQ4fchI4Hbr0YYTCMdAgsmIKROKsXnnXmSkpQ66bYLejR32BACxN6zW/PRtCPZ1Djlumn0RUpf9F6SAD72f/QOu8i8hBf3QF89ByrL/gtKYPMzZ+kmSBNuGl+HY8ylErxPa3ClIWfZdqFP6tzOVAn70fPI4XFVfQWlMRsqy70JfNGvg8bYtbyLY14WUC78T8p+XiID0BC0WFKfIXQaNEkcGxsjUieMRCATw9SkaCaogsjSxeakg+5Y/Ie/ufw58ZVz7fwAA4+TFAIDetc/AXb0VaZf/DzKv/x0Cjh50vf3QCc/Zt+VN9O14HynL70bWTY9AUOvQ+foDkAL9/4b2PZ/A116NrBsfhmlmGbrf/+PAv7nf2g7Hnk+RdM7NYfypieLbytIsKDhnIOowDIyRCUX5SDAa0edwDrmtxOCSoaLwUxoSoTQlD3y5q7dClZQNbf50iF4nHHtXI3np7dAXzoQ2awLSVv4A3pZyeFsqhj2fJEmwb38XiYuuhaFkITQZxUi7+EcIOHrhqtwMAPD3NEE/YQE06YVImHMRRJcNorsPAND7n6eQfN6tUGhDs7saEQ110Qz2GohGDANjJCczHbnZmei1WIfcVqzzQCkMbWgUS6SgH86DX8A040IIggBvezUgBgYN4atT86E0p8PbOnwYCNg6EHRaBj1GoTVCmzNp4DGajGJ4mw9C9HvhqdsJpSkFCr0ZjgOfQ1BpYJh4Zjh/TKK4lmXWYX7R8S/zUeTinIExolAoMH/mNJRX1UCSpEFrcjUKCUU6D2rcsfuJ1VX5FUSPA8bS8wEAotMCKFVQ6AZvdao0JiHotAx7jqCj/7jCmDT4MYYkBJ1WAIBp+oXwddaj9R/fhVJvRtpl90H0OGDb8DIyv/lbWL78J1zlX0KVlIXUlf8NVQK3hCYKlavn5nG/gSjFMDCGZkwpgTnBBGufHcmJg7f1LNG7YzoMOPb+B/pxc6FKSD35nU+DoFQhddl/DTrW/eFjSJh7CXwdtXBXbUb2t55A35Y3YVnzd6Rf8b9hrYcoXigE4JsLCuQug04RLxOModysDEyeUIzOnt4ht+VovTAogjJUFX4BWyc8DXtgmrl84JjCmAwEAxA9jkH3DTqtx11NoDT1HxcPjwIMPMZlhfJrowVHeBr2wt/TgIQ5F8PTuBf6cfOg0OhgmHwWPI37Tv2HIqJBzp2Yjtwkbq8erRgGxpAgCDhjZimCgSCCwcFv/AoBGK93y1RZeDn2rYbSkAj9+PkDx7RZEwCFCu6GPQPH/D3NCPZ1QZszedjzqBIzoTQmw9Owe+CY6HXB23po2MdIAR96Vz+N1OX3QFAoAUmEJB7+dxeDkKTYnqdBNJauX1B48jtRxGIYGGOlkycgNTkJ3b3WIbdNjMFVBZIkwrFvDYyl5/e/IR+m0BphmnEhLJ89C0/DXnjbq9Hz0WPQ5kyGNvfoG3vLM9+Bq3ITgP4wlTDvMtg2rYKragt8XfXo/vBRqEwpMExcNOS5rZteg37cPGgyxwMAtLlT4arcBF9nHew7P4Aud0qYf3qi+JCdqMPSyRlyl0GngXMGxliSOQFzSqdg9frNyEwffP08WR1AmtqHbr9GpupCz1O/G8G+LphmXDjktpTz70SvoEDXOw9BCvqhK56D1Au/O+g+gd5miN6jIcm84CpIfg96Pn0CoscJXd5UZFzzKwiqwf9mvq56uCrWI/vWJwaOGSYvhqdpH9pfvg/q1FykXfL/QvzTEsWna+fnsx9BlGOjIhnsPnAIj/z9JRTm5UCnHfwmVuXSY52VS3OIKDooFQI23rcUWYncgjia8TKBDKZMKEZOZjo6u4dOJByvd8fsREIiij1LJmUwCMQAhgEZaLUaLJozA312x5DtiRUCMM04dJdCIqJIdAOXE8YEhgGZzJgyEUaDHg7n0EmDk41OqGJ8R0Iiin65SXqcOzFd7jIoBBgGZFKUn4OS4gK0dXYPuU2rkGJyZQERxZZbzixkU6IYwTAgE4VCgfMWzUMwGITXN7RrYanRCQGc20lEkSnZoMYN3FsgZjAMyGjWtEkoys9Ba0fXkNvMqiAKdR4ZqiIiOrnbFhfDqOXq9FjBMCAjnVaL8xbNh9PpHrIjIQBMNzmGeRQRkbwSdCrcsrhI7jIohBgGZDZ/5jRkZaSho6tnyG2ZGj8y1EMvIRARyemWRUUw69Ryl0EhxDAgsyRzAs4+YzZ6rbYhywwBjg4QUWQxaJS4/axiucugEGMYiAAL58xAcqIZPRbrkNuKdB6kqPxjXxQR0TBuXFiIZGPsbJlO/RgGIkBuVgbmz5w27KUCQQDmmftkqIqIaDCtSoE7zx4ndxkUBgwDEWLx/NnQ63TocwzdfbBA50WWxitDVURER103Px/pCVq5y6AwYBiIECXFBZg2aTxa2zuHvX0+RweISEYapQLfOW+83GVQmDAMRAiFQoFzF86DIAhwuYfuL5Cp8aNA55ahMiIi4Loz8pGdqJe7DAoThoEIMmvqREyfNAGNLW3D3j4/wc5dCYlozCXq1fjhBRPlLoPCiGEggqhUKpQtWQyVSjns3IFkdQAT9BwdIKKx9f3zS7iCIMYxDESY0kkTMKd0Cppa24fdd2Bugh1Kjg4Q0RgZl27EzYvYgyDWMQxEGIVCgRVLzoJRr4fFNnTSoEkVxBTj0FEDIqJw+PlFU6FW8q0i1vG/cASaUJSPRXNmoLW9a9jRgVkJdqgFUYbKiCienDsxHUsmZ8hdBo0BhoEIJAgClp27CMmJCejqsQy5XaeQMC/BLkNlRBQvVAoBP794itxl0BhhGIhQ+TlZOGfhXHR09UAUh44CTDU6kc4mRkQUJjcuLMSEjAS5y6AxwjAQwZYuPgOZ6SloP842xWclWbnUkIhCLkmvxg8uKJG7DBpDDAMRLDMtFecvXoBeixXBYHDI7anqAEo5mZCIQuwHF5QgycClhPGEYSDCnbtoHgpys9HY0j7s7XMS7DApA2NcFRHFqpl5ibhpUZHcZdAYYxiIcEnmBFx64Xnw+XxwuFxDblcrJJyZaJOhMiKKNRqlgEeumQmlQpC7FBpjDANRYOGc6Zg3cxoamlqHXWpYoPOimH0LiOg0/fDCSZw0GKcYBqKASqXCFWVLkZyUiPbO7mHvsyjRxr0HiOiUzcg1465zxsldBsmEYSBKFORmY+WSxei12uD1DV1SaFCKbHNMRKdErQAevXYWLw/EMYaBKHL+WQswpWQc6htbhr19isGFTI13jKsiomj3o2W8PBDvGAaiiF6nwxVlS6HRqNFrHTppUBCA85Ks0PByARGNUGm2CXedM17uMkhmDANRpnTSBJy7cB5a2zuH3XsgQRXk6gIiGhG1Anjsm3N5eYAYBqKNIAi4+IJzDu890DbsfSYY3BivH7oMkYjoWD9eNgkTMkxyl0ERgGEgCqUkJR7ee8APh3P4N/3FiTZuRkRExzUnz4w7eXmADmMYiFKL5s7AwrkzUd/UgmBw6BwBjULCkmQLexcQ0RDJOgX+est8Xh6gAQwDUUqpVOKai5ehMDcHdU3Dry7I1PjZ6piIBlFAwtM3zUdGgk7uUiiCMAxEsfTUZHzjkmUQBKDHMvykwRkmB/K0njGujIgi1ffPK8bC8Wlyl0ERhmFARkVFRXjsscdO6xxzp0/BhWcvRFtHJ3w+/5Dbjyw3NCiGrjwgovhyRp4ePyibJncZFIEYBkZAEIQTfv3yl788pfNu27YNd91112nXdtmyJZg2aQJqGpqG7V2gU4pYmmyBgvMHiOJWqlbCM7ctlrsMilCCNNy7Bw3S3n60ffCqVavwwAMP4NChQwPHTCYTTKb+5TmSJCEYDEKlUo1pjbUNzXj02X/C7w8gPydr2Pscchqw3pY0pnURkfxUgoh/f3shZhWly10KRSiODIxAVlbWwFdiYiIEQRj4vqKiAgkJCfj4448xd+5caLVabNiwATU1NbjsssuQmZkJk8mE+fPnY82aNYPO+/XLBIIg4Nlnn8UVV1wBg8GAkpISvPfeeyOqcVxhHq5acQHcbg9sdsew95lkdKHUOPxtRBS7/nfZeAYBOiGGgRD5n//5H/zud79DeXk5ZsyYAYfDgZUrV2Lt2rXYtWsXysrKcMkll6CxsfGE53nwwQdxzTXXYO/evVi5ciVuuOEG9Pb2jqiGcxfOxXmL5qGppQ1+//B7DCww9yGfEwqJ4say8SbctmSq3GVQhGMYCJFf/epXuPDCCzF+/HikpKRg5syZ+Pa3v43S0lKUlJTg17/+NcaPH3/ST/q33norvvnNb2LChAl46KGH4HA4sHXr1hHVoFAocPVFF2JKyThU1zcOO39AEIAlyRYkq4ZONiSi2DI+UcATt54ldxkUBRgGQmTevHmDvnc4HLj33nsxZcoUJCUlwWQyoby8/KQjAzNmzBj4u9FohNlsRmdn54jrMCeYcOOVFyE1ORH1x9l/QKOQsCylFzquMCCKWWmaAFZ991xo1Uq5S6EowDAQIkajcdD39957L95++2089NBDWL9+PXbv3o3p06fD5/Od8DxqtXrQ94IgQBRH14VwfGE+brziIgACOrp6hr1PgiqIC5ItUHKFAVHMMQgBvHDbAqQlGk9+ZyIAYzvlPY5s3LgRt956K6644goA/SMF9fX1Y/b882eVoqvXglff/Rg6rQaJ5qG9yrO0PpyVZMU6a/KY1UVE4aVCAH+4bAJKi4ZfVUQ0HI4MhElJSQneeust7N69G3v27MH1118/6k/4p0MQBJSdtxjnL16IptYOuD3e4es0uDHTxC2LiWKBIIn43vxEXLyQGwvR6DAMhMmjjz6K5ORknHnmmbjkkkuwfPlyzJkzZ0xrUCqVuO6y5Zg/axqq6xsRCAy/wmBegh0lbHlMFN0kCVePB+65/Gy5K6EoxE2H4kB3rxV//sfLqGlowpSScRCEoZ3KRAn4wpKMWo9ehgqJ6HSdl+HBX+++GDqtVu5SKApxZCAOpKUk4bZrL0dGWgpqG5uHvY9CAM5LtqBQ5x7j6ojodM1IcOKJu8oYBOiUMQzEieKCXNx45cVQKZVo6+ga9j4KAViabGGXQ6IoUqR14NlvX4AEE1cO0KljGIgj82ZMxZUrLkCf3YEei3XY+ygF4IKUXmRrhp9wSESRo0DVh+fvOBsZaSlyl0JRjmEgziw/dxEuXXYeOrt70Wu1DXsflQAsS+lFhvrEeyIQkXzyhV48ffMZKM7PkbsUigEMA3FGoVDgyhXn46Lzz0Z7ZzesfcMvK1QrJJSl9iCNgYAo4uRKXXj4mlmYNnG83KVQjGAYiENKpRLXXLwMZectRktbB/qO0+VQczgQsI8BUeTICbbjwYsnY8Hs6XKXQjGEYSBOqVQqXHdpGS48ZxGaWtvhcA6/z4BOIWElRwiIIkJOoA0/uaAY55+1QO5SKMYwDMQxjUaNGy5fiSVnnoG6phY4XcMvK9QrRVyU2oNcrjIgkk2uvxX3LRuPSy88b9i9QohOBzcdIrg9Hjy36l18uWUHxhfmw6DXDXs/UQLWWZNQ4zaMcYVE8S0/0IL7yibhovPPYRCgsODIAEGv0+HWb1yKM+fORG1D03H7GCgE4LwkK6YZh59jQEShV+hvwk9XTmEQoLDiyAANsDuceOaVN7F1936MO8EIAQDssZuwzW4ew+qI4osAERP9dfjBxXNRdt6ZDAIUVgwDNEif3YHnX38Xm3fsRUFeNswn2NWs0qXHemsSJPBFiiiUVAhiWqASd1+6GBeevZBBgMKOYYCGcHs8ePmtj7B201ZkZ6QhJSnxuPdt9Gix1pKMoMQrTkShoIUPM/2H8O0rlmDp4jMYBGhMMAzQsPz+AN748D/4+LMNSEo0IzM99bj37fCpsbo3BR5ROYYVEsUes+TE9GAV7rhyGc5bNI9BgMYMwwAdlyiK+HDterz50RrodFrkZWce976OgBJrLMno9mvGsEKi2JEe7MFsZRNuumIFzjpjNoMAjSmGATohSZLwxebtePWdjxEQgyjOzz3ui1RQAjbaElHpYvc0otHI8zVgntmJb11zGWZOnSh3ORSHGAZoRLbu3o+X3nwffXYHJhQVQKE4/hyBcqcBm22JEDmxkOiElBBR7DqEhfk63H7tFSguyJW7JIpTDAM0Ygcqa/Dca++grbMLE8cXQaU8/hyBTp8aa3pT4OI8AqJhJSq8KLDtxZlT8nHbdZcjM+3483KIwo1hgEalrrEF/1j1NqrqGk+4WyEAuIMKrLUko92nHcMKiSJfodKCTNtBLF0wC9dfvhLmBJPcJVGcYxigUeux2PCvtz7A5p17kZWeirSU5OPeV5SArX1m7HfyxY5ILYiYLNYjxdeJSy44B5ctWwK1WiV3WUQMA3RqfD4/3lv9BT5cux4KhQJF+TknnP1c49ZhgzUJfu5HQHEqVeXDOMd+pBkU+OZlZTj7jDlcMUARg2GATpkkSdiyax9effdjdPVYUFJceMJPOY6AEl9ak9DKywYUZyZqrUjq2otx+Tm46aqLMW3ieLlLIhqEYYBOW31TK17893sor6pFUX4uTMbjdzWUJOCgy4BtfWYEOEpAMU4jiJihaITG1oQFs6fjm5evQEZqitxlEQ3BMEAhYbM78Nq7H2Pdlh1ITUo64Y6FAGALKLHOkoxOblJEMSpb40F+3wEkaYFLLzwXy89dzPkBFLEYBihkAoEAPvliI9759AsEggEU5+dBqTz+p39RAvY6TNhpT+CeBBQztIKImbouCB0VGF+Yh+svX4nSSRPkLovohBgGKOR27i/Hqnc/RX1LKwrzck7Y+RAAevwqrLMkozegHqMKicKjWOfCOG8tPA4rzpw3C9ddWobU5OM3+iKKFAwDFBbdvVa8+fEabNi6CxqNGoW52SfctTAoATvtCdjrMLElMkUdozKAhaZeeNuqYDIacNmyJbjw7AVQqXhZgKIDwwCFjSiK2LR9D97+ZC1a2jtRVJALk+H4kwsBoNevwmZbItq44oCigAAJUwwulKAFHe1tmDiuENdfvhKTJxTLXRrRqDAMUNi1d/Xg3x+uxlc798CgNyA/J/Ok66tr3Tps7TPDEeQnK4pMSSo/FiX0wNlWB6VCgbMXzMGVK85HkjlB7tKIRo1hgMZEIBDAl1t24p1PP0NXjwXFBXkn3MoYAAISsOfwpYMgLx1QhFALImYY7cjxtaCruwsTigtw5YrzMXvaZG4iRFGLYYDGVHNbB1a9/yl27D2IRHMCcjLTT/oCag8osaXPjHqPfoyqJBpKgITJBhem6XrQ3tQEg16HC85egBVLzkLCSSbJEkU6hgEacz6fH2s3bsUHa9ahx2JDQW7WiBq1tHg12GxLhJWrDmiMFencmJfQB1dvOyxWG6ZPLsGVK87n3ACKGQwDJJum1na8v+ZLbNm1D6IkoigvB1rNiTchEiXgoNOIPQ4T3GyPTGGWofZhQaINpmAf6hpbkJKUiIuWnoXzz1oAnZaTXCl2MAyQrERRxO6Dh/D+6nWoqK6DOcGE3KyMEy5DBICAKKDcZcBehgIKg0RlAPPMfcjXONHU2g6v14s506fi6pUXoCA3W+7yiEKOYYAigtvjwZdbduLjzzegrbMbuVkZSEk6+WYtAQkodxoZCigk9IogZifYMVHnQGdXN3qtfSjIzcLKpWfjrPmzuG8AxSyGAYooHd09+PizjdiwbSfcHi+K8nOg15141QHQHwoqePmATlGiMoDpJgcm6J2wWK3o6OxGRloKLjx7Ec5dOHdEc1qIohnDAEUcSZJQUV2H91Z/gb3lVdBpNcjLzhpRk5cjoWCvwwQXQwGdRIbahxkmBwp1HvTZ7Whu64A5wYRzFszBBWcvRGbaiRtuEcUKhgGKWH5/AJt37sHHn29EfXMrDDodcrMzoFGffDVBQAIOOY3Y7zTCzo2LaBAJ+VovZpocyNL64HJ70NDcCo1GjfkzS7FyyVkoys+Ru0iiMcUwQBHP5fbgq517sWb9V6hrboVBp0VuduaIQoEkAY1eLQ44TGjlFsdxTQEJ4/VuzDA5kKwOwOvzoam1HWJQROnkEqxcehamTRzPjYMoLjEMUNRwuT3YsmsfVq/fjLqm0YUCALD4VTjoNKLarYdfOvFqBYodBkUQJQYXphqdMCpFOF1utLR3QhRFjC/Mx8qlZ2Hu9CmcHEhxjWGAoo7L7cHW3fv7Q0FjC3Q6LfJGEQr8ooAatx7lLgN6/Cfe14CikwISCnQeTDS4kKf1QoCEPrsDrR1dUCmVmDyhGEsXn4FZUydBq+XvABHDAEUtt8eDLbv2Y836r1Db2AytVoOczAzodSO/HNDtU6PcZUAtRwtiQorKj4kGFybo3dApRUiShB6LFR1dPTDo9Zg5dSLOXTgPpZPGQ6nkBFOiIxgGKOq5Pf0jBWs3bkVdYwtEUURWRhqSzAkjvv4bkIBmjw61Hh2aPDoGgyiiFUSMN7gwUe9GmsYPoH8zq47uXnT3WpCcaMYZM6fh7AVzMaEon3MCiIbBMEAxw+8PYN+hKmzcthv7yqvQ53AgJTkJGWkpUI3iU2BAApo8OtS69WjyahFgMIg4akFEntaLYr0bhToPlIff3z1eLzq6emB3OJGRloKz5s/GmfNmIS87U96CiSIcwwDFHEmS0NjShi279mHTjj3o6O6FRq1CVnraqLvLBUQBjV4t6hgMZGdSBlCg9aJA50G21jsQAIJBET0WC7p6rFCplMjPzsTi+bOwcM5MpCaffBdLImIYoBhnszuw5+AhbNy2G1V1jXC5PUhNTkRaajLUo5w9fiQYNHl0aPNp4OD+BWEmIU3tR6HOgwKdB6nqwNFbJAl2pwsdXd3w+vxIS07C3OlTMGf6VEyZUAyNhp0tiUaDYYDigiiKqGloxrY9+7F193509VgAAClJiUhNTjylZWW2gBKtXi1avVq0+TTwcMfD06YRRGRqfCg4HACMSnHQ7T6fHx3dPbD12WE0GFBSXICFc2ZgxpSSEfWyIKLhMQxQ3LE7nCivrsO+8irsPngIvVYbJAlITT71YCBJQG9ANRAO2n0aTkIcAbMygEyNb+ArSRXA1+f3+Xx+9Nps6LX0QaEQkJOZjgWzp2P2tMkoys85aYdLIjo5hgGKa312Byqq67CnvBJ7y6vQY7FCEASkJiciJTlpVBMPjyVKQLdfjS6fBj1+NXoCKlj8aoiI35nsisPD/kfe+DM0Phi+9skf6L8E4HJ70GOxwe5wQKVUIjUlCaWTJmDWtMmYNnHciJpXEdHIMQwQHWY7EgwOVmJfRRV6rTYAgDnBhKTEBBh0utNaliZKgCWgQo9fjV6/uj8k+NXwxeAIglYRRLIq0P+l9iNFFUCaxgfVcf75RFFEn92JHqsVHo8XOp0WWelpmF06GZPGFWFCUT6MBv3Y/hBEcYRhgGgYR4LBgUPVOFhVh16rDW6PByqVColmE5LMCdBpQ9PrwB5QotevRl9QCcfhL+fhPyN5HoICEsyqAMyqABKVQSQe/nuSKjDsJ/5jSZIEj9eHPrsD1j47AsEgzCYjCnOzMbt0MiaOK0Rhbja3CCYaIwwDRCfh8/nR3NaBuqYWVNY24FBtPSw2O3w+HzQaNRLNCUgyJ4x4O+TRCEjoDwgB1aCQ4JUE+EUF/JLQ/3X47wFJgHQalyKUggi9ov9LpxChVwYHvh/0d4UIrUIccn3/eESxvyeAze6Aw+FEUBSh1WpgNpkweXwRSidPQElxIbLSU7kpEJEMGAaIRsnt8aChuQ31za0or6pDTUMTrH12iEERCqUCRoMeJqMBJoMBavXYf7INiAJ8h0NCQBIgSQIEQYICgOIkf4bqfdgfCKDP7kSfwwG32wMIgFGvR0piIiaNL0RxQR7ysjORl53B6/9EEYBhgOg09dkdqG9uRUt7Z/8IQmMLLLY+OFxuBAJBCAJg0OthNOphMuih02pj5tOvKIpwe7xwut1wuTxwezyQJAkKhQJmkxHZmemYNL4IhbnZyM3KQHZGGnsCEEUghgGiEBNFERabHR3dPejo6kFrRydqGprR2d0Lp8sNj9cLQRAgCAJ0Wg20Gg20x/ypUiojKiwEg0H4/AF4vF64PV54PF54vN6B2/U6LQx6PTLSUlCYm42sjDRkpaciLzsTyYnmiPpZiGh4DANEY8ThdA0EhG6LDb0WGzq7e9BlscDl9sDr9cPr8yEQDA5c9Ver1dBo1FAqFFAplVAoFVAqlFApFVAqlVAoFFAqD9+mUAx645UkCZIkQTz8pyRKkCBBFKWB2/yBAPz+AHx+P/z+APyB/j+PpRAEqNVq6LQaGAx6ZKenIS87A6kpyUhJSkR6ShLSU5M53E8UxRgGiGQmSdLA5Dqb3YG+w3/a+hzo7O5Br7UPbm//p/FgUEQwGERQPPznoO/7J/T1/y8tQBAwMAJx5Evxte/VahXUKhX0Oi3MCSYkJ5qRkmiG0WiAyaCH0aCHQa+DUa8/PFHSxGF+ohjEMEAUJSRJgs/nh8/vh88fgNfng/+Yv/v8fgT8AQgKRf+IgUIBhULoH0EQDv+pEKBUKAeO67RamIx6aDUaDucTxTGGASIiojgXe1ufERER0agwDBAREcU5hgEiIqI4xzBAREQU5xgGiIiI4hzDABERUZxjGCAiIopzDANERERxjmGAiIgozjEMEBERxTmGASIiojjHMEBERBTnGAaIiIjiHMMAERFRnGMYICIiinMMA0RERHGOYYCIiCjOMQwQERHFOYYBIiKiOMcwQEREFOf+Pz0NhV7gDp0GAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the data sets representations using a pie chart just to see the distribution of the data\n",
    "labels = 'Train', 'Validation', 'Test'\n",
    "sizes = [len(train_df), len(val_df), len(test_df)]\n",
    "explode = (0.1, 0, 0)\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "ax1.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb58f7c8-2621-4fb3-9a48-cde04ee33fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 25000\n",
    "sequence_length = 30\n",
    "\n",
    "# define a custom standardization function that convert to lowercase and strips all punctuations except \"[\" and \"]\" (so we can tell apart \"start\" from \"[start]\").\n",
    "strip_chars = string.punctuation\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ce42dd7-24f4-409b-a2f3-51065339e574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68e7d9c1-493d-4327-9c8e-b3043ea0cef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 15:34:30.073590: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-02 15:34:30.073797: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-02 15:34:30.073948: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-02 15:34:30.123313: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-02 15:34:30.123517: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-02 15:34:30.123686: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-02 15:34:30.123816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6263 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# tokenize the data using our custom standardization function\n",
    "source_vectorization = keras.layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "target_vectorization = keras.layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1,\n",
    "    # add +1 token to our target sentences since they'll be shifted right by 1 during training\n",
    "    standardize=custom_standardization,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c96b8d1f-5dfc-45a3-bc51-61dfa2835d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"The button battery for my computer's timer died.\",\n",
       "       'I only have one suggestion.', 'He refused to pay.', ...,\n",
       "       'Why would I want to sue you?',\n",
       "       \"You don't know what you're missing.\",\n",
       "       \"I'm guessing this is yours.\"], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index all tokens in the source and target sentences\n",
    "train_source_texts = train_df['source'].values\n",
    "train_target_texts = train_df['target'].values\n",
    "train_source_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0268f523-1e97-4b71-8535-baa29c545640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.preprocessing.text_vectorization.TextVectorization at 0x7a7e8d0329b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_vectorization.adapt(train_source_texts)\n",
    "target_vectorization.adapt(train_target_texts)\n",
    "source_vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dfa21ec-0ce7-4136-9654-ed093ad3396b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89467"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sample = random.randint(0, len(train_df))\n",
    "random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7845fda-4fb1-4239-bb7b-00758d1e036b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source texts (one random sample): I am accustomed to living alone.\n",
      "Target texts (one random sample): [start] Je suis habitué à vivre seul. [end]\n",
      "Source vectors (one random sample): tf.Tensor(\n",
      "[   2  118 1647    4  519  182    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0], shape=(30,), dtype=int64)\n",
      "Target vectors (one random sample): tf.Tensor(\n",
      "[   2    4   26 1221    9  380  179    3    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0], shape=(31,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Source texts (one random sample):\", train_source_texts[random_sample])\n",
    "print(\"Target texts (one random sample):\", train_target_texts[random_sample])\n",
    "print(\"Source vectors (one random sample):\", source_vectorization(train_source_texts[random_sample]))\n",
    "print(\"Target vectors (one random sample):\", target_vectorization(train_target_texts[random_sample]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6804b8ab-1c1a-426c-9bab-713531117237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_vectorization.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02274abe-fdf8-4455-afe1-6f8aa7ece8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source decoded texts (one random sample): i am accustomed to living alone                         \n",
      "Target decoded texts (one random sample): [start] je suis habitué à vivre seul [end]                        \n"
     ]
    }
   ],
   "source": [
    "# Display the decoding of the vectorized text (from vector back to text) just to test the vectorization\n",
    "source_decoded_text = ''\n",
    "for i in range(len(source_vectorization(train_source_texts[random_sample]))):\n",
    "    source_decoded_text += source_vectorization.get_vocabulary()[\n",
    "                               source_vectorization(train_source_texts[random_sample])[i]] + ' '\n",
    "print(\"Source decoded texts (one random sample):\", source_decoded_text)\n",
    "\n",
    "target_decoded_text = ''\n",
    "for i in range(len(target_vectorization(train_target_texts[random_sample]))):\n",
    "    target_decoded_text += target_vectorization.get_vocabulary()[\n",
    "                               target_vectorization(train_target_texts[random_sample])[i]] + ' '\n",
    "print(\"Target decoded texts (one random sample):\", target_decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a5264af-4137-4592-961a-129f5360bab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source vectors (shape): (122934, 30)\n",
      "Target vectors (shape): (122934, 31)\n"
     ]
    }
   ],
   "source": [
    "# Display the shape of our vectorized data\n",
    "train_source_vectors = source_vectorization(train_source_texts)\n",
    "train_target_vectors = target_vectorization(train_target_texts)\n",
    "print(\"Source vectors (shape):\", train_source_vectors.shape)\n",
    "print(\"Target vectors (shape):\", train_target_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c9c56-7077-4a22-b78b-88c2380b8cc1",
   "metadata": {},
   "source": [
    "# Building the Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6894b785-f0a0-4909-9ba5-679c1ff33011",
   "metadata": {},
   "source": [
    "**Positional Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84c2843b-9348-441a-9568-ffb7ac8ddc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = keras.layers.Embedding(input_dim=input_dim, output_dim=output_dim)\n",
    "        self.position_embeddings = keras.layers.Embedding(input_dim=sequence_length, output_dim=output_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1) # create the positional information\n",
    "        embedded_positions = self.position_embeddings(positions) # embed the positions \n",
    "        return embedded_tokens + embedded_positions # add the token and position embeddings to create the positional embeddings\n",
    "        \n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(PositionalEmbedding, self).get_config()\n",
    "        config.update({\n",
    "            \"input_dim\": self.input_dim,\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f67f08b-b785-4027-b58e-9b8c9167ca5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 15:34:41.165111: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 3776532480 exceeds 10% of free system memory.\n",
      "2024-07-02 15:34:41.380721: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 3776532480 exceeds 10% of free system memory.\n",
      "2024-07-02 15:34:41.909040: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 3776532480 exceeds 10% of free system memory.\n",
      "2024-07-02 15:34:42.111225: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 3776532480 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source texts (one random sample): The party's over.\n",
      "Target texts (one random sample): [start] La fête est finie. [end]\n",
      "Source vectors (one random sample): tf.Tensor(\n",
      "[   5 5339  178    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0], shape=(30,), dtype=int64)\n",
      "Target vectors (one random sample): tf.Tensor(\n",
      "[   2   10  294   15 3623    3    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0], shape=(31,), dtype=int64)\n",
      "Source embedded vectors (one random sample): tf.Tensor(\n",
      "[[-0.00650704  0.01890611  0.04230333 ...  0.03570325 -0.00179838\n",
      "  -0.00820101]\n",
      " [ 0.01616565  0.0315378   0.05838604 ... -0.0440284   0.06817309\n",
      "   0.09248477]\n",
      " [ 0.03959115 -0.06508946  0.00781979 ...  0.02839359  0.04449531\n",
      "  -0.03617071]\n",
      " ...\n",
      " [-0.00736199 -0.0147505   0.04904447 ...  0.02357408 -0.04441813\n",
      "   0.01642568]\n",
      " [ 0.06363912 -0.01061284  0.02566089 ...  0.0311004   0.01113222\n",
      "  -0.02614175]\n",
      " [-0.00538218 -0.01044484  0.02018225 ... -0.0309271   0.02049686\n",
      "   0.02203733]], shape=(30, 256), dtype=float32)\n",
      "Target embedded vectors (one random sample): tf.Tensor(\n",
      "[[ 0.02526331 -0.00296401 -0.04419458 ... -0.09233078 -0.05355301\n",
      "  -0.04140874]\n",
      " [-0.09580642  0.01568482 -0.07539818 ... -0.02756362  0.04216108\n",
      "  -0.04411526]\n",
      " [ 0.02563446 -0.04357069  0.0132482  ... -0.01236031  0.02864579\n",
      "   0.00641397]\n",
      " ...\n",
      " [-0.0163179  -0.00920733  0.06144048 ...  0.03230219 -0.02682322\n",
      "  -0.07717506]\n",
      " [-0.02925933 -0.03737731 -0.03163856 ...  0.02765694  0.04323792\n",
      "  -0.07343005]\n",
      " [-0.01570362  0.02543929  0.05745871 ... -0.00282806 -0.03960092\n",
      "  -0.05827351]], shape=(30, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Display a random sample before and after embbeding just to test our class\n",
    "embed_dim = 256\n",
    "with tf.device('cpu:0'):\n",
    "    train_source_embedded = PositionalEmbedding(\n",
    "        sequence_length=sequence_length,\n",
    "        input_dim=max_tokens,\n",
    "        output_dim=embed_dim,\n",
    "        name=\"source_embedding\",\n",
    "    ) (train_source_vectors)\n",
    "\n",
    "    train_target_embedded = PositionalEmbedding(\n",
    "        sequence_length=sequence_length,\n",
    "        input_dim=max_tokens,\n",
    "        output_dim=embed_dim,\n",
    "        name=\"target_embedding\",\n",
    "    ) (train_source_vectors)\n",
    "\n",
    "    random_sample = random.randint(0, len(train_df))\n",
    "    print(\"Source texts (one random sample):\", train_source_texts[random_sample])\n",
    "    print(\"Target texts (one random sample):\", train_target_texts[random_sample])\n",
    "    print(\"Source vectors (one random sample):\", source_vectorization(train_source_texts[random_sample]))\n",
    "    print(\"Target vectors (one random sample):\", target_vectorization(train_target_texts[random_sample]))\n",
    "    print(\"Source embedded vectors (one random sample):\", train_source_embedded[random_sample])\n",
    "    print(\"Target embedded vectors (one random sample):\", train_target_embedded[random_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b4dadc8-9bb3-484e-9254-b5df44101284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source embedded vectors (shape): (122934, 30, 256)\n",
      "Target embedded vectors (shape): (122934, 30, 256)\n"
     ]
    }
   ],
   "source": [
    "# Display the shape of our embedded data just to test the class\n",
    "print(\"Source embedded vectors (shape):\", train_source_embedded.shape)\n",
    "print(\"Target embedded vectors (shape):\", train_target_embedded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b96b724-42be-439e-ab52-ee52c6e1263c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a3c90e7-751a-45ab-acd0-4dddc23a98e7",
   "metadata": {},
   "source": [
    "**The Attention mechanism**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78a4895-b23d-4636-9d76-615cdf56ad8a",
   "metadata": {},
   "source": [
    "**1. Causal Masking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d573371d-fc30-4ada-98d8-8b6abbfdcfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# credits to OpenAI for that one (https://github.com/openai/gpt-2/blob/master/src/model.py)\n",
    "def shape_list(x):\n",
    "    \"\"\"Deal with dynamic shape in tensorflow cleanly.\"\"\"\n",
    "    static = x.shape.as_list()\n",
    "    dynamic = tf.shape(x)\n",
    "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]\n",
    "\n",
    "def attention_mask(nd, ns, *, dtype):\n",
    "    \"\"\"1's in the lower triangle, counting from the lower right corner.\n",
    "    Same as tf.matrix_band_part(tf.ones([nd, ns]), -1, ns-nd), but doesn't produce garbage on TPUs.\n",
    "    \"\"\"\n",
    "    i = tf.range(nd)[:,None]\n",
    "    j = tf.range(ns)\n",
    "    m = i >= j - ns + nd\n",
    "    return tf.cast(m, dtype)\n",
    "\n",
    "def mask_attn_weights(w):\n",
    "    # w has shape [batch, heads, dst_sequence, src_sequence], where information flows from src to dst.\n",
    "    _, _, nd, ns = shape_list(w)\n",
    "    b = attention_mask(nd, ns, dtype=w.dtype)\n",
    "    b = tf.reshape(b, [1, 1, nd, ns])\n",
    "    w = w*b - tf.cast(1e10, w.dtype)*(1-b)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa54da3c-cb9f-4db5-bf1b-f00c312c8536",
   "metadata": {},
   "source": [
    "# display the causal masking of a random tensor just to test the function\n",
    "random_tensor = tf.random.uniform(shape=(1, 1, 5, 5), minval=0, maxval=1, dtype=tf.float32)\n",
    "print(\"Masked attention weights:\", mask_attn_weights(random_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eed4064-cea2-4dd3-81e1-b18ed5118366",
   "metadata": {},
   "source": [
    "**2. Scaled Dot-Product Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2230ed0-13ae-42fa-ab29-0a7e62f15884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, use_causal_mask=False):\n",
    "    d_k = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scores = tf.matmul(q, k, transpose_b=True) # Matmul of Q and K\n",
    "    scaled_scores = scores / tf.math.sqrt(d_k) # Scale\n",
    "    if use_causal_mask:\n",
    "        scaled_scores = mask_attn_weights(scaled_scores) # Mask (opt.)\n",
    "    weights = tf.nn.softmax(scaled_scores, axis=-1) # SoftMax\n",
    "    output = tf.matmul(weights, v) # Matmul of SoftMax and V\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40745dc8-4e60-4553-80fe-c18f5bc7e67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 15:34:48.800199: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 3776532480 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled dot product attention (shape): (122934, 1, 30, 256)\n"
     ]
    }
   ],
   "source": [
    "# display the shape of our attention output just to test the function\n",
    "with tf.device('cpu:0'):\n",
    "    input = train_source_embedded\n",
    "    input = tf.expand_dims(input, axis=1)\n",
    "    print(\"Scaled dot product attention (shape):\", scaled_dot_product_attention(input, input, input, use_causal_mask=True).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8252c00f-63f1-4785-ad11-34f4992f1eac",
   "metadata": {},
   "source": [
    "**3. Multi-Head Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad1852b7-1722-4914-8d76-6cd4d830b80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, h, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.h = h\n",
    "        if embed_dim % h != 0:\n",
    "            raise ValueError(\n",
    "                f\"dimension of the embedding space = {embed_dim} should be divisible by number of heads = {h}\"\n",
    "            )\n",
    "        self.q_linear = keras.layers.Dense(embed_dim)\n",
    "        self.k_linear = keras.layers.Dense(embed_dim)\n",
    "        self.v_linear = keras.layers.Dense(embed_dim)\n",
    "        self.concat_linear = keras.layers.Dense(embed_dim)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, shape=(batch_size, -1, self.h, self.embed_dim // self.h))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def concat_heads(self, x, batch_size):\n",
    "        x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        return tf.reshape(x, (batch_size, -1, self.embed_dim))\n",
    "\n",
    "    def call(self, q, k, v, use_causal_mask=False):\n",
    "        batch_size = tf.shape(k)[0]\n",
    "        q = self.q_linear(q)\n",
    "        k = self.k_linear(k)\n",
    "        v = self.v_linear(v)\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "        attention = scaled_dot_product_attention(q, k, v, use_causal_mask)\n",
    "        concat = self.concat_heads(attention, batch_size)\n",
    "        concat = self.concat_linear(concat)\n",
    "        return concat\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(MultiHeadAttention, self).get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"h\": self.h,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57017852-6133-45a9-9f18-f4931756a8bc",
   "metadata": {},
   "source": [
    "**The Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbfeb65a-46b0-4d39-84a4-36f867422f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.layer_norm_1 = keras.layers.LayerNormalization()\n",
    "        self.layer_norm_2 = keras.layers.LayerNormalization()\n",
    "        self.global_self_attention = MultiHeadAttention(embed_dim=embed_dim, h=num_heads)\n",
    "        self.feed_forward = keras.Sequential(\n",
    "            [keras.layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        \n",
    "    def call(self, x):\n",
    "        # Post layer normalization + residual connections\n",
    "        x = self.layer_norm_1(x + self.global_self_attention(q=x, k=x, v=x))\n",
    "        x = self.layer_norm_2(x + self.feed_forward(x))\n",
    "        return x\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7f9f63-4992-4b4c-904f-e9ccefe5da16",
   "metadata": {},
   "source": [
    "**The Decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c50054e-f961-40fd-9b4c-78cc3f24c1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.causal_self_attention = MultiHeadAttention(embed_dim=embed_dim, h=num_heads)\n",
    "        self.cross_attention = MultiHeadAttention(embed_dim=embed_dim, h=num_heads)\n",
    "        self.feed_forward = keras.Sequential(\n",
    "            [keras.layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layer_norm_1 = keras.layers.LayerNormalization()\n",
    "        self.layer_norm_2 = keras.layers.LayerNormalization()\n",
    "        self.layer_norm_3 = keras.layers.LayerNormalization()\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, x, context):\n",
    "        # Post layer normalization + residual connections\n",
    "        x = self.layer_norm_1(x + self.causal_self_attention(q=x, k=x, v=x, use_causal_mask=True))\n",
    "        x = self.layer_norm_2(x + self.cross_attention(q=x, k=context, v=context))\n",
    "        x = self.layer_norm_3(x + self.feed_forward(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b00977d-5f17-4bea-a2b9-3ca36956ae60",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "def format_dataset(source, target):\n",
    "    source_vectors = source_vectorization(source)\n",
    "    target_vectors = target_vectorization(target)\n",
    "    return ({\n",
    "        \"source\": source_vectors, # encoder_inputs\n",
    "        \"target\": target_vectors[:, :-1], # decoder_inputs (truncate by 1 to keep it at the same length as decoder_outputs, which is shifted right by 1).\n",
    "    }, target_vectors[:, 1:]) # decoder_outputs\n",
    "\n",
    "def make_dataset(df):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((df[\"source\"].values, df[\"target\"].values))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()\n",
    "\n",
    "train_ds = make_dataset(train_df)\n",
    "val_ds = make_dataset(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "851656ef-cfa5-4869-9fca-24c0d33988c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CacheDataset element_spec=({'source': TensorSpec(shape=(None, 30), dtype=tf.int64, name=None), 'target': TensorSpec(shape=(None, 30), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 30), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf27e050-9a1a-41d4-b3bc-51046b05bd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Inputs: (64, 30)\n",
      "Decoder Inputs: (64, 30)\n",
      "Decoder Outputs: (64, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 15:34:55.390659: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "# display the shape of the first batch of data in the dataset just to see what it looks like\n",
    "for batch in train_ds.take(1):\n",
    "    print(\"Encoder Inputs:\", batch[0][\"source\"].shape)\n",
    "    print(\"Decoder Inputs:\", batch[0][\"target\"].shape)\n",
    "    print(\"Decoder Outputs:\", batch[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2bc7eb1-2b3e-4f51-80d6-bb2210304b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 512 # dimension of the embedding space\n",
    "dense_dim = 2048 # dimension of the feed forward network (a rule of thumb is to use 4 times the size of the embeddings)\n",
    "num_heads = 8\n",
    "\n",
    "# the transformer body\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"source\")\n",
    "x = PositionalEmbedding(sequence_length, max_tokens, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"target\")\n",
    "x = PositionalEmbedding(sequence_length, max_tokens, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "\n",
    "# the transformer head\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "decoder_outputs = keras.layers.Dense(max_tokens, activation=\"softmax\")(x)\n",
    "\n",
    "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "569a15e5-6a38-4cd4-b73e-d320bde276f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 15:35:11.648381: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-07-02 15:35:12.177209: I external/local_xla/xla/service/service.cc:168] XLA service 0x7a7d7abc6fb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-02 15:35:12.177231: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Laptop GPU, Compute Capability 8.9\n",
      "2024-07-02 15:35:12.181358: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1719927312.233318  276714 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1921/1921 [==============================] - 142s 72ms/step - loss: 0.9398 - accuracy: 0.8595 - val_loss: 0.5872 - val_accuracy: 0.9001 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1921/1921 [==============================] - 137s 71ms/step - loss: 0.5649 - accuracy: 0.9027 - val_loss: 0.4908 - val_accuracy: 0.9114 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1921/1921 [==============================] - 138s 72ms/step - loss: 0.4680 - accuracy: 0.9143 - val_loss: 0.4582 - val_accuracy: 0.9163 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1921/1921 [==============================] - 140s 73ms/step - loss: 0.4104 - accuracy: 0.9219 - val_loss: 0.4352 - val_accuracy: 0.9199 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1921/1921 [==============================] - 140s 73ms/step - loss: 0.3686 - accuracy: 0.9276 - val_loss: 0.4270 - val_accuracy: 0.9215 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1921/1921 [==============================] - 140s 73ms/step - loss: 0.3352 - accuracy: 0.9323 - val_loss: 0.4271 - val_accuracy: 0.9235 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1921/1921 [==============================] - 141s 74ms/step - loss: 0.3078 - accuracy: 0.9366 - val_loss: 0.4214 - val_accuracy: 0.9253 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1921/1921 [==============================] - 141s 73ms/step - loss: 0.2846 - accuracy: 0.9402 - val_loss: 0.4197 - val_accuracy: 0.9266 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1921/1921 [==============================] - 138s 72ms/step - loss: 0.2629 - accuracy: 0.9437 - val_loss: 0.4243 - val_accuracy: 0.9258 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1921/1921 [==============================] - 139s 72ms/step - loss: 0.2431 - accuracy: 0.9468 - val_loss: 0.4202 - val_accuracy: 0.9273 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "transformer.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "EPOCHS = 10\n",
    "checkpoint_filepath = 'checkpoint.weights.h5'\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1,\n",
    "        patience=3,\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=6,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True\n",
    "    ),\n",
    "]\n",
    "    \n",
    "transformer.fit(train_ds, \n",
    "                epochs=EPOCHS, \n",
    "                callbacks=callbacks_list,\n",
    "                validation_data=val_ds)\n",
    "\n",
    "transformer.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71d55897-63ba-4305-9da1-5485ffc47927",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vocab = target_vectorization.get_vocabulary()\n",
    "target_index_lookup = dict(zip(range(len(target_vocab)), target_vocab))\n",
    "max_decoded_sentence_length = 30\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = target_vectorization(\n",
    "            [decoded_sentence])[:, :-1]\n",
    "        predictions = transformer(\n",
    "            [tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = target_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93ce671d-9f30-4d96-af0d-18aec3f37b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She sang a Japanese song for us.\n",
      "[start] elle a chanté une chanson pour nous [end]\n",
      "\n",
      "I just felt a little dizzy. That's all.\n",
      "[start] je me suis un peu senti que cest tout [end]\n",
      "\n",
      "He has no conscience.\n",
      "[start] il na aucune conscience [end]\n",
      "\n",
      "Can you tell me why Tom isn't here?\n",
      "[start] peuxtu me dire pourquoi tom nest pas là [end]\n",
      "\n",
      "This is giving me a headache.\n",
      "[start] Ça me donne mal à la tête [end]\n",
      "\n",
      "They will agree on that.\n",
      "[start] ils vont daccord sur ça [end]\n",
      "\n",
      "She won't make it.\n",
      "[start] elle ne le fera pas [end]\n",
      "\n",
      "Who makes the decisions here?\n",
      "[start] qui fait des décisions ici [end]\n",
      "\n",
      "Tom doesn't like frog legs.\n",
      "[start] tom naime pas la différence les jambes [end]\n",
      "\n",
      "Can you do a headstand?\n",
      "[start] peuxtu te faire la tête [end]\n",
      "\n",
      "Take that back.\n",
      "[start] prends ce nest [end]\n",
      "\n",
      "I sometimes hear my father singing in the bath.\n",
      "[start] jentends parfois mon père chanter dans le bain [end]\n",
      "\n",
      "Tom's well.\n",
      "[start] tom est bien [end]\n",
      "\n",
      "Tom makes a lot of spelling mistakes.\n",
      "[start] tom fait de nombreuses fautes dorthographe [end]\n",
      "\n",
      "Tom doesn't yet know whether he can go or not.\n",
      "[start] tom ne sait pas encore sil peut se rendre ou non [end]\n",
      "\n",
      "Tell me if you're happy.\n",
      "[start] dismoi si vous êtes heureux [end]\n",
      "\n",
      "I feel my age.\n",
      "[start] je me sens de mon âge [end]\n",
      "\n",
      "We can't let them do that.\n",
      "[start] nous ne pouvons les laisser faire cela [end]\n",
      "\n",
      "I think you're nuts.\n",
      "[start] je pense que vous êtes dingues [end]\n",
      "\n",
      "Don't ask too many questions.\n",
      "[start] ne posez pas trop de questions [end]\n",
      "\n",
      "I think it's better not to try it.\n",
      "[start] je pense quil est préférable de ne pas de ne pas y essayer [end]\n",
      "\n",
      "I'm by your side.\n",
      "[start] je suis à tes côtés [end]\n",
      "\n",
      "She is in a green dress.\n",
      "[start] elle est dans une robe verte [end]\n",
      "\n",
      "I work different hours every day.\n",
      "[start] je travaille différent de tous les jours [end]\n",
      "\n",
      "It's not legally binding.\n",
      "[start] ce nest pas de façon [UNK] [end]\n",
      "\n",
      "I will watch it.\n",
      "[start] je vais la montre [end]\n",
      "\n",
      "Will you join our club?\n",
      "[start] veuxtu joindre nos club [end]\n",
      "\n",
      "It matters to me.\n",
      "[start] Ça va me voir [end]\n",
      "\n",
      "Grab as much as you need.\n",
      "[start] [UNK] tant que tu en as besoin [end]\n",
      "\n",
      "She did her best to help him.\n",
      "[start] elle le meilleur coup de son mieux [end]\n",
      "\n",
      "Were you hurt?\n",
      "[start] Étiezvous mal [end]\n",
      "\n",
      "I enjoy being a teacher.\n",
      "[start] jaime être enseignant [end]\n",
      "\n",
      "Tom got very mad.\n",
      "[start] tom sest très en colère [end]\n",
      "\n",
      "I really don't feel like talking right now.\n",
      "[start] je nai vraiment pas envie de parler maintenant [end]\n",
      "\n",
      "I saw the picture you took of that fish.\n",
      "[start] jai vu la photo que tu aies pris du poisson [end]\n",
      "\n",
      "You're disappointed, aren't you?\n",
      "[start] tu es déçu nestce pas [end]\n",
      "\n",
      "I've never cared about such things.\n",
      "[start] je ne me suis jamais souciais de telles choses [end]\n",
      "\n",
      "Tom maintained that he was innocent.\n",
      "[start] tom a demandé quil était innocent [end]\n",
      "\n",
      "My hobby is music.\n",
      "[start] mon passetemps est la musique [end]\n",
      "\n",
      "I can't let you go in there alone.\n",
      "[start] je ne peux pas vous laisser aller seul làdedans [end]\n",
      "\n",
      "Turn on the rice cooker, please.\n",
      "[start] allume le riz sil vous plaît [end]\n",
      "\n",
      "The entrance is on the other side of the building.\n",
      "[start] lentrée est de lautre côté de lautre côté du bâtiment [end]\n",
      "\n",
      "I'm visiting a friend of mine in the hospital.\n",
      "[start] je suis visite à un ami à moi à lhôpital [end]\n",
      "\n",
      "I fell in love with her at first sight.\n",
      "[start] je suis tombé amoureux delle au premier regard [end]\n",
      "\n",
      "Everybody needs something to believe in.\n",
      "[start] tout le monde a besoin de quelque chose à croire [end]\n",
      "\n",
      "How can I repay you?\n",
      "[start] comment puisje vous rembourser [end]\n",
      "\n",
      "That's why I quit.\n",
      "[start] cest pourquoi jai démissionné [end]\n",
      "\n",
      "I can't imagine what you're going through.\n",
      "[start] je ne peux pas imaginer ce que tu vas faire à travers [end]\n",
      "\n",
      "Is all of this money yours?\n",
      "[start] tout estil de cet argent [end]\n",
      "\n",
      "Going to church doesn't make you a Christian any more than standing in a garage makes you a car.\n",
      "[start] allez léglise ne vous rendil plus de [UNK] [end]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's translate 50 random sentences\n",
    "for i in range(50):\n",
    "    random_index = np.random.randint(0, len(test_df))\n",
    "    input_sentence = test_df[\"source\"].iloc[random_index]\n",
    "    print(input_sentence)\n",
    "    print(decode_sequence(input_sentence))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2d77c2-f61e-44fa-92fc-c7cf4d1eafd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
